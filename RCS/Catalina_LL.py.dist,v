head	1.72;
access;
symbols;
locks; strict;
comment	@# @;


1.72
date	2007.02.22.23.55.45;	author kenneth;	state Exp;
branches;
next	1.71;

1.71
date	2007.02.16.23.38.51;	author kenneth;	state Exp;
branches;
next	1.70;

1.70
date	2007.02.16.01.56.19;	author kenneth;	state Exp;
branches;
next	1.69;

1.69
date	2007.02.08.20.43.02;	author mmargo;	state Exp;
branches;
next	1.68;

1.68
date	2007.01.27.03.13.43;	author kenneth;	state Exp;
branches;
next	1.67;

1.67
date	2006.10.13.18.37.18;	author mmargo;	state Exp;
branches;
next	1.66;

1.66
date	2006.10.12.22.55.39;	author mmargo;	state Exp;
branches;
next	1.65;

1.65
date	2006.07.18.00.07.02;	author mmargo;	state Exp;
branches;
next	1.64;

1.64
date	2006.07.05.21.17.15;	author mmargo;	state Exp;
branches;
next	1.63;

1.63
date	2005.12.05.20.25.56;	author mmargo;	state Exp;
branches;
next	1.62;

1.62
date	2005.04.07.17.13.49;	author kenneth;	state Exp;
branches;
next	1.61;

1.61
date	2005.04.07.17.09.37;	author kenneth;	state Exp;
branches;
next	1.60;

1.60
date	2005.03.29.22.04.55;	author kenneth;	state Exp;
branches;
next	1.59;

1.59
date	2005.03.29.07.32.05;	author kenneth;	state Exp;
branches;
next	1.58;

1.58
date	2005.03.28.20.06.05;	author kenneth;	state Exp;
branches;
next	1.57;

1.57
date	2004.10.04.17.44.37;	author kenneth;	state Exp;
branches;
next	1.56;

1.56
date	2004.09.24.01.58.11;	author kenneth;	state Exp;
branches;
next	1.55;

1.55
date	2004.08.23.22.08.03;	author kenneth;	state Exp;
branches;
next	1.54;

1.54
date	2004.08.18.17.11.30;	author kenneth;	state Exp;
branches;
next	1.53;

1.53
date	2004.08.17.15.46.45;	author kenneth;	state Exp;
branches;
next	1.52;

1.52
date	2004.08.11.17.43.48;	author kenneth;	state Exp;
branches;
next	1.51;

1.51
date	2004.05.17.18.13.15;	author kenneth;	state Exp;
branches;
next	1.50;

1.50
date	2004.05.11.22.08.30;	author kenneth;	state Exp;
branches;
next	1.49;

1.49
date	2004.05.07.23.05.07;	author kenneth;	state Exp;
branches;
next	1.48;

1.48
date	2004.05.07.17.38.48;	author kenneth;	state Exp;
branches;
next	1.47;

1.47
date	2004.05.03.18.20.16;	author kenneth;	state Exp;
branches;
next	1.46;

1.46
date	2004.05.03.06.10.08;	author kenneth;	state Exp;
branches;
next	1.45;

1.45
date	2004.04.11.21.55.24;	author kenneth;	state Exp;
branches;
next	1.44;

1.44
date	2004.04.11.05.41.31;	author kenneth;	state Exp;
branches;
next	1.43;

1.43
date	2004.04.11.04.38.09;	author kenneth;	state Exp;
branches;
next	1.42;

1.42
date	2004.04.10.21.35.23;	author kenneth;	state Exp;
branches;
next	1.41;

1.41
date	2004.03.05.01.15.32;	author kenneth;	state Exp;
branches;
next	1.40;

1.40
date	2004.02.24.04.32.09;	author kenneth;	state Exp;
branches;
next	1.39;

1.39
date	2004.02.05.17.54.42;	author kenneth;	state Exp;
branches;
next	1.38;

1.38
date	2003.12.11.21.52.47;	author kenneth;	state Exp;
branches;
next	1.37;

1.37
date	2003.12.10.20.39.57;	author kenneth;	state Exp;
branches;
next	1.36;

1.36
date	2003.10.28.21.59.21;	author kenneth;	state Exp;
branches;
next	1.35;

1.35
date	2003.08.07.22.13.32;	author kenneth;	state Exp;
branches;
next	1.34;

1.34
date	2003.08.07.22.10.20;	author kenneth;	state Exp;
branches;
next	1.33;

1.33
date	2003.08.06.23.17.50;	author kenneth;	state Exp;
branches;
next	1.32;

1.32
date	2003.07.18.16.52.57;	author kenneth;	state Exp;
branches;
next	1.31;

1.31
date	2003.06.26.18.06.54;	author kenneth;	state Exp;
branches;
next	1.30;

1.30
date	2003.01.10.23.31.29;	author kenneth;	state Exp;
branches;
next	1.29;

1.29
date	2002.11.06.19.15.28;	author kenneth;	state Exp;
branches;
next	1.28;

1.28
date	2002.11.01.19.39.08;	author kenneth;	state Exp;
branches;
next	1.27;

1.27
date	2002.09.04.21.57.02;	author kenneth;	state Exp;
branches;
next	1.26;

1.26
date	2002.05.16.15.59.52;	author kenneth;	state Exp;
branches;
next	1.25;

1.25
date	2002.05.16.15.44.57;	author kenneth;	state Exp;
branches;
next	1.24;

1.24
date	2002.04.19.21.07.01;	author kenneth;	state Exp;
branches;
next	1.23;

1.23
date	2002.02.27.01.36.13;	author kenneth;	state Exp;
branches;
next	1.22;

1.22
date	2002.02.22.19.15.31;	author kenneth;	state Exp;
branches;
next	1.21;

1.21
date	2002.01.16.18.57.04;	author kenneth;	state Exp;
branches;
next	1.20;

1.20
date	2002.01.14.18.41.52;	author kenneth;	state Exp;
branches;
next	1.19;

1.19
date	2002.01.03.17.06.18;	author kenneth;	state Exp;
branches;
next	1.18;

1.18
date	2002.01.03.00.25.32;	author kenneth;	state Exp;
branches;
next	1.17;

1.17
date	2001.12.20.18.17.09;	author kenneth;	state Exp;
branches;
next	1.16;

1.16
date	2001.12.18.19.29.29;	author kenneth;	state Exp;
branches;
next	1.15;

1.15
date	2001.12.17.23.25.06;	author kenneth;	state Exp;
branches;
next	1.14;

1.14
date	2001.12.14.18.12.22;	author kenneth;	state Exp;
branches;
next	1.13;

1.13
date	2001.12.01.01.32.46;	author kenneth;	state Exp;
branches;
next	1.12;

1.12
date	2001.12.01.00.13.02;	author kenneth;	state Exp;
branches;
next	1.11;

1.11
date	2001.11.28.22.05.26;	author kenneth;	state Exp;
branches;
next	1.10;

1.10
date	2001.11.27.19.21.33;	author kenneth;	state Exp;
branches;
next	1.9;

1.9
date	2001.11.27.00.09.52;	author kenneth;	state Exp;
branches;
next	1.8;

1.8
date	2001.11.07.17.09.59;	author kenneth;	state Exp;
branches;
next	1.7;

1.7
date	2001.11.06.23.05.56;	author kenneth;	state Exp;
branches;
next	1.6;

1.6
date	2001.11.01.00.13.54;	author kenneth;	state Exp;
branches;
next	1.5;

1.5
date	2001.10.04.17.27.38;	author kenneth;	state Exp;
branches;
next	1.4;

1.4
date	2001.09.13.17.44.39;	author kenneth;	state Exp;
branches;
next	1.3;

1.3
date	2001.09.12.23.52.41;	author kenneth;	state Exp;
branches;
next	1.2;

1.2
date	2001.09.11.22.09.41;	author kenneth;	state Exp;
branches;
next	1.1;

1.1
date	2001.09.11.19.59.59;	author kenneth;	state Exp;
branches;
next	;


desc
@LoadLeveler module
@


1.72
log
@added initiatormap to attribute list
commented out node_list.reverse()
@
text
@# SP-specific Catalina names
# get node info with llstatus -l
# get job info with llq -l
# get initiatormap from queryjob2 (Data Access API)
# job info needed to match jobs to nodes:
# - Requirements expression (from queryjob2)
# - Adapter Requirement (from llq -l)
# - initiator map (from queryjob2)
# - job class (queryjob2)
# - user
# - group
# - account
# Don't see how to get Adapter Requirement from API...

import os
import re
import string
import time
import types
import copy
# Importing Catalina in order to use the insert_new_job function
# in update_job_priorities and Now_float
import Catalina

import sys
import traceback

JOBSUFFIX='.0'
SUBMIT_OUTPUT_PATTERN=r'llsubmit: The job "(?P<job_id>.*)" has been submitted.'
JOB_UPDATE_ATTRIBUTE_list = [
  'state',
  'job_class',
  'Dispatch_Time',
  'wall_clock_used',
  'allocated_hosts',
  'task_hosts',
  'completion_time',
  'resource_dict_list',
  'requested_resource_list',
  'req_dict_list',
  'initiatormap',
  'cat_requirements_string'
  ]

start_job_returncode_reo = re.compile("^rc from ll_start_job is >(?P<code>\d+)<$", re.MULTILINE)

def get_scheduler_time() :
    if Catalina.SERVERMODE == 'SIM' :
        Now_float = float(os.system(Catalina.TIME_SIM))
    else :
        Now_float = time.time()
    return Now_float

def initialize_resource(resource_name) :
    new_resource = {}
    new_resource['name'] =  resource_name
    new_resource['Disk'] = 0
    new_resource['Machine'] = None
    new_resource['Arch'] = None
    new_resource['OpSys'] = None
    new_resource['Pool'] = None
    new_resource['ConfiguredClasses_list'] = None
    new_resource['AvailableClasses'] = None
    new_resource['Adapter'] = None
    new_resource['Feature'] = ''
    new_resource['properties_list'] = []
    new_resource['Max_Starters'] = None
    new_resource['Memory'] = 0
    new_resource['Cpus'] = 0
    new_resource['ConsumableMemory'] = 0
    new_resource['ConsumableCpus'] = 0
    new_resource['State'] = None
    new_resource['speculative_state'] = None
    new_resource['State_Change_Time'] = Catalina.Now_float
    new_resource['resourcesmap'] = ''
    return new_resource

def initialize_job_step(job_step_name) :
    new_job_step = {}
    new_job_step['name'] = job_step_name
    new_job_step['QOS'] = '0'
    new_job_step['user'] = None
    new_job_step['state'] = None
    new_job_step['job_class'] = None
    new_job_step['wall_clock_limit'] = None
    new_job_step['wall_clock_used'] = None
    new_job_step['comment'] = None
    new_job_step['account'] = None
    new_job_step['group'] = None
    new_job_step['adapter'] = None
    new_job_step['requirements'] = None
    new_job_step['ConfiguredClasses_list'] = []
    new_job_step['AvailableClasses_list'] = []
    new_job_step['properties_list'] = []
    new_job_step['system_queue_time'] = None
    new_job_step['submittime'] = None
    new_job_step['dispatchtime'] = None
    new_job_step['completiontime'] = None
    new_job_step['system_priority_int'] = None
    new_job_step['system_priority_mark_string'] = None
    new_job_step['ineligible_reason'] = None
    new_job_step['reservation_binding'] = []
    new_job_step['job_start_warns_int'] = 0
    new_job_step['resource_amount_int'] = 0
    new_job_step['run_at_risk_int'] = 0
    new_job_step['preemptible'] = 0
    new_job_step['preempting'] = 0
    return new_job_step

def get_runjob_dict() :
    finished_reo = re.compile("^qj FINISHED$")
    finished_found = 0
    runjob_dict = {}
    stepid_reo = re.compile(r"^stepid:(?P<stepid>(?P<fromhost>.*)\.(?P<cluster>\d+)\.(?P<proc>\d+))$")
    if Catalina.SERVERMODE == 'SIM' and Catalina.QJ_SIM != None :
        cmd = Catalina.QJ_SIM
    else :
        cmd = Catalina.HOMEDIR + '/___QJ_PLACEHOLDER___'
    for rawline in os.popen(cmd).readlines() :
        finished_mo = finished_reo.match(rawline)
        if finished_mo != None :
            finished_found = 1
            continue
        step_dict = {}
        line = string.strip(rawline)
        elements = string.split(line,'#cat_delim#')
        for element in elements :
            name_value_list = string.split(element, ':')
            if len(name_value_list) == 1 :
                name_value_list.append('')
            if name_value_list[0] == 'stepid' :
                stepid = name_value_list[1]
                stepid_mo = stepid_reo.match(element)
                if stepid_mo != None :
                    step_dict['fromhost'] = stepid_mo.group('fromhost')
                    step_dict['cluster'] = stepid_mo.group('cluster')
                    step_dict['proc'] = stepid_mo.group('proc')
                    stepid = stepid_mo.group('stepid')
            step_dict[name_value_list[0]] = name_value_list[1]
        if not step_dict.has_key('fromhost') or \
           not step_dict.has_key('cluster') or \
           not step_dict.has_key('proc') or \
           not step_dict.has_key('initiatormap') :
            print "Did not find all runjob info!"
        else :
            runjob_dict[stepid] = step_dict
    if finished_found != 1 :
        raise 'IncompleteQJ'
    return runjob_dict

# Martin W. Margo
# 11/30/2005 10:58 AM
# Modified cancel_job to accepts another argument message but dont' do anything
# about it. This arguments works for PBS only
def cancel_job(job_step, events_db_handle, message=None) :
    cmd_string = Catalina.CANCELCMD + ' ' + job_step['name']
    output = 'llcancel: Cancel command has been sent to the central manager.'
    if Catalina.SERVERMODE == 'NORMAL' :
        return_string = os.popen(cmd_string).read()
        mo = re.match(output, return_string)
        if mo == None :
            raise 'CancelJobFailure', job_step
    else :
        print cmd_string
        return_string = ''
    event = {
      'name' : 'cancel_job',
      'cmd' : cmd_string,
      'return_string' : return_string
      }
    Catalina.log_event(event, events_db_handle)

def preempt_job(job_step, events_db_handle) :
    PREEMPTJOB='___PREEMPTJOB_PLACEHOLDER___'
    #cmd_string = PREEMPTJOB + ' ' + job_step['name'] + ' PREEMPT_STEP'
    cmd_string = PREEMPTJOB + ' ' + job_step['name']
    #output = 'llpreempt: Preempt command has been sent to the central manager.'
    if Catalina.SERVERMODE == 'NORMAL' :
        return_string = os.popen(cmd_string).read()
        #mo = re.match(output, return_string)
        #if mo == None :
        #    raise 'PreemptJobFailure', job_step
    else :
        print cmd_string
        return_string = ''
    event = {
      'name' : 'preempt_job',
      'cmd' : cmd_string,
      'return_string' : return_string
      }
    Catalina.log_event(event, events_db_handle)

def cancel_bad_jobs(jobs_db_handle, resources_db_handle, events_db_handle) :
    jobs_dict = jobs_db_handle[0]
    jobs_list = jobs_dict.values()
    resources_dict = resources_db_handle[0]
    resources_list = resources_dict.values()
    for job in jobs_list :
        if job['state'] == 'Starting' :
            if Catalina.Now_float - job['Dispatch_Time'] > \
              Catalina.JOB_START_TIME_LIMIT :
                event = {
                  'name' : 'bad_job',
                  'type' : 'JOB_START_TIME_LIMIT violation',
                  'job' : job['name'],
                  'now' : Catalina.Now_float,
                  'Dispatch_Time' : job['Dispatch_Time']
                  }
                Catalina.log_event(event, events_db_handle)
                print "canceling %s in state %s" % (job['name'], job['state'])
                try :
                    cancel_job(job, events_db_handle)
                except :
                    continue
                message = """
%s
job (%s) (user %s), in state Starting for %s seconds,
has exceeded JOB_START_TIME_LIMIT (%s).  This job will
be canceled.  Please investigate the cause of job start
failure.""" % \
(time.asctime(time.localtime(Catalina.Now_float)), job['name'],
  job['user'], Catalina.Now_float - job['Dispatch_Time'], Catalina.JOB_START_TIME_LIMIT)
                subject = "Job exceeded JOB_START_TIME_LIMIT, %s, %s" % \
                  (job['name'], job['user'])
                recipient = Catalina.MAIL_RECIPIENT + ' ' + job['user']
                Catalina.warn(message, subject, recipient)
        if job['state'] in ['Starting', 'Running'] :
            down_hosts_list = []
            for host in job['allocated_hosts'] :
                if resources_dict.has_key(host) and \
                   resources_dict[host]['State'] == 'Down' and \
                  Catalina.Now_float - resources_dict[host]['State_Change_Time'] \
                  > Catalina.RESOURCE_DOWN_TIME_LIMIT :
                    event = {
                      'name' : 'bad_job',
                      'type' : 'RESOURCE_DOWN_TIME_LIMIT violation',
                      'job' : job['name'],
                      'host' : host,
                      'State' : resources_dict[host]['State'],
                      'now' : Catalina.Now_float,
                      'State_Change_Time' : job['Dispatch_Time']
                      }
                    Catalina.log_event(event, events_db_handle)
                    down_hosts_list.append(host)
            if len(down_hosts_list) > 0 :
                event = {
                  'name' : 'bad_job',
                  'type' : 'RESOURCE_DOWN_TIME_LIMIT violation',
                  'job' : job['name'],
                  'now' : Catalina.Now_float,
                  'State_Change_Time' : job['Dispatch_Time']
                  }
                Catalina.log_event(event, events_db_handle)
                print "Down node allocated for job %s in state %s with down nodes %s" % \
                  (job['name'], job['state'], down_hosts_list)
                message = """
%s
job (%s) (user %s), in state %s has LoadL down nodes:
Please check to see if this job actually has Down nodes.
If it does have Down nodes, check to see if the job is in state
Remove Pending (RP in llq).  If so, the job may be stuck waiting
for a response from the down nodes.  It may be necessary to issue:
""" % \
(time.asctime(time.localtime(Catalina.Now_float)), job['name'],
  job['user'], job['state'], )
                for host in down_hosts_list :
                    purge_line = "\n/usr/lpp/LoadL/full/bin/llctl -h %s purge %s" % \
                      (jobs_dict[job['name']]['fromhost'], host)
                    message = message + purge_line
                subject = "Job has LoadLeveler Down Nodes %s, %s" % \
                  (job['name'], job['user'])
                recipient = Catalina.MAIL_RECIPIENT
                Catalina.warn(message, subject, recipient)
        ## bug 549. Check if there is any typo given by the user (consumable resources, typically in shared nodes)
        if job.has_key('modified'):
            if job['modified'] == 'true' :
                ## notified is artificial field set on the job database. 
                if not job.has_key('notified') :
                    
                    recipient = Catalina.MAIL_RECIPIENT + ' ' + job['user']
                    subject = 'Unrecognized consumable resources. Reset to default'
                    message = """
job (%s) (user %s) has unrecognized consumable resources specification. 
To continue scheduling, Catalina assumes that the user wanted 1 CPU per task
and/or 3GB of RAM per task. 

Your job may fail because of these assumptions.
Please carefully read your job script and correct any errors.""" % (job['name'],job['user'])
                    Catalina.warn(message,subject,recipient)
                      
                    ## add this to the job database
                    job['notified']=''
                            
                    event = {
                        'name': 'unrecognized_specification',
                        'type': 'UNKNOWN resources violation',
                        'job': job['name'],
                        'now': Catalina.Now_float,
                        'State_Change_Time' : job['Dispatch_Time']
                    }
                    Catalina.log_event(event,events_db_handle)

        # end of patch for bug 549
                      
                
def get_job_step_state(job_step) :
    LoadL_state = job_step['state']
    if LoadL_state == 'Starting' :
        return 'STARTING'
    if LoadL_state == 'Running' :
        return 'RUNNING'
    elif LoadL_state == 'Idle' :
        return 'IDLE'
    elif LoadL_state == 'Completed' :
        return 'COMPLETED'
    elif LoadL_state == 'Removed' :
        return 'REMOVED'
    else :
        return 'OTHER'

def get_job_steps_dict() :
    runjob_dict = get_runjob_dict()
    if Catalina.SERVERMODE == 'SIM' :
        LLQ = Catalina.HOMEDIR + '/' + 'llq_sim'
    else :
        LLQ = '/usr/lpp/LoadL/full/bin/llq -l | /usr/bin/grep -e "Job Step Id" -e "Adapter Requirement"'
    job_steps = {}
    new_job_step_id = None
    found_start = 0
    job_string = ''
    id_adapter_reo = re.compile(r"Job Step Id:.*?(\S+).*?Adapter Requirement:\s*(\S*?)$",re.MULTILINE | re.DOTALL);
    #adapterreq_reo = re.compile( r"""(^\s*Job\ Step\ Id:\ (?P<job_step_id>\S+))
    #         (.*)
    #         (^\s*Adapter\ Requirement:\ ?(?P<adapter>\S*)$)"""
    #    ,re.MULTILINE | re.DOTALL | re.VERBOSE)

    # (Machine == {"ds271" "ds272" "ds273"}) && (Arch == "R6000") && (OpSys == "AIX52")
    machine_req_pat = r"\(Machine == \{.*?\}\) &&"
    machine_req_reo = re.compile(machine_req_pat)
    llqstring = os.popen(LLQ).read()
    llqlist = id_adapter_reo.findall(llqstring)
    #print "llqlist (%s)" % llqlist
    for linetuple in llqlist :
        # parse the lines, setting values in new_job_step
        #adapterreq_mo = adapterreq_reo.search(line)
        line_job_id = linetuple[0]
        line_adapter = linetuple[1]
        llq_job_step_name = line_job_id
        llq_job_step_adapter = line_adapter
        if runjob_dict.has_key(line_job_id) :
            required_keys_tuple = (
              'user',
              'class',
              'wall_clock_limit',
              'account',
              'group',
              'requirementsmap',
              'state',
              'initiatormap',
              'fromhost',
              'cluster',
              'comment',
              'proc',
              'submittime'
              )
            job_step_id = line_job_id
            present_keys_list = runjob_dict[job_step_id].keys()
            for required_key in required_keys_tuple :
                if required_key not in present_keys_list :
                    print "required key (%s) not found" % required_key
                    job_string = ''
                    continue
            new_job_step = initialize_job_step(job_step_id)
            new_job_step['user'] = runjob_dict[job_step_id]['user']
            if Catalina.RM_TO_CAT_JOB_dict.has_key(runjob_dict[job_step_id]['state']) :
                new_job_step['state'] = Catalina.RM_TO_CAT_JOB_dict[runjob_dict[job_step_id]['state']]
            else :
                new_job_step['state'] = 'Unknown'
            new_job_step['job_class'] = runjob_dict[job_step_id]['class']
            new_job_step['wall_clock_limit'] = string.atof(runjob_dict[job_step_id]['wall_clock_limit'])
            new_job_step['account'] = runjob_dict[job_step_id]['account']
            new_job_step['group'] = runjob_dict[job_step_id]['group']
            requirements_map = runjob_dict[job_step_id]['requirementsmap']
            single_requirements_list = string.split(requirements_map, '+')
            new_job_step['requirements'] = single_requirements_list[0]
            new_job_step['adapter'] = llq_job_step_adapter
            new_job_step['fromhost'] = runjob_dict[job_step_id]['fromhost']
            new_job_step['cluster'] = runjob_dict[job_step_id]['cluster']
            new_job_step['proc'] = runjob_dict[job_step_id]['proc']
            new_job_step['SubmitTime'] = string.atof(runjob_dict[job_step_id]['submittime'])
            if runjob_dict[job_step_id].has_key('dispatchtime') :
                new_job_step['Dispatch_Time'] = string.atof(runjob_dict[job_step_id]['dispatchtime'])
            if runjob_dict[job_step_id].has_key('completiontime') :
                new_job_step['completion_time'] = string.atof(runjob_dict[job_step_id]['completiontime'])
            if runjob_dict[job_step_id].has_key('wall_clock_used') :
                new_job_step['wall_clock_used'] = string.atof(runjob_dict[job_step_id]['wall_clock_used'])
            if runjob_dict[job_step_id].has_key('comment') :
                new_job_step['comment'] = runjob_dict[job_step_id]['comment']
                elements = string.split(runjob_dict[job_step_id]['comment'], ';')
                for element in elements :
                    string.strip(element)
                    fields = string.split(element, '=')
                    if string.strip(fields[0]) == 'Catalina_res_bind' :
                        res_ids_list = []
                        raw_res_ids = string.split(fields[1], ',')
                        for id in raw_res_ids :
                            res_ids_list.append(string.strip(id))
                        new_job_step['reservation_binding'] =  res_ids_list
                    elif string.strip(fields[0]) == 'Catalina_preemptible' :
                        if len(fields) >= 2 :
                            preemptible_string = string.strip(fields[1])
                            if preemptible_string in ['Yes','YES','yes','Y','y','1'] :
                                new_job_step['preemptible'] = 1
                        else :
                            new_job_step['preemptible'] =  1
                    elif string.strip(fields[0]) == 'Catalina_preempting' :
                        if len(fields) >= 2 :
                            preempting_string = string.strip(fields[1])
                            if preempting_string in ['Yes','YES','yes','Y','y','1'] :
                                new_job_step['preempting'] = 1
                        else :
                            new_job_step['preempting'] =  1
                    elif string.strip(fields[0]) == 'QOS' :
                        QOS = string.strip(fields[1])
                        try :
                            testint = string.atoi(QOS)
                        except :
                            new_job_step['QOS'] =  '0'
                        else :
                            new_job_step['QOS'] =  QOS
                    elif string.strip(fields[0]) == 'Catalina_local_admin_priority' :
                        local_admin_priority_string = string.strip(fields[1])
                        new_job_step['local_admin_priority_string'] = local_admin_priority_string
                    elif string.strip(fields[0]) == 'Catalina_local_user_priority' :
                        local_user_priority_string = string.strip(fields[1])
                        new_job_step['local_user_priority_string'] = local_user_priority_string
                    elif string.strip(fields[0]) == 'Catalina_run_at_risk' :
                        run_at_risk_string = string.strip(fields[1])
                        #print "fromhost, proc, cluster (%s, %s, %s)" % \
                        #  (new_job_step['fromhost'], new_job_step['proc'], new_job_step['cluster'])
                        #print "run_at_risk_string (%s)" % run_at_risk_string
                        if run_at_risk_string in ['Yes','YES','yes','Y','y','1'] :
                            new_job_step['run_at_risk_int'] = 1
            new_job_step['initiatormap'] = runjob_dict[job_step_id]['initiatormap']
            resourcemap_list = string.split(new_job_step['initiatormap'], '+')
            # For some reason, initiatormap is reversed 
            #resourcemap_list.reverse()
            if runjob_dict[job_step_id].has_key('node_usage') :
                if runjob_dict[job_step_id]['node_usage'] == 'SHARED' :
                    new_job_step['node_usage'] = 'node_shared'
                else :
                    new_job_step['node_usage'] = 'node_exclusive'
            else :
                # if node_usage not found, assume NOT_SHARED
                new_job_step['node_usage'] = 'node_exclusive'
            new_job_step['resource_amount_int'] = len(resourcemap_list)
            # To support multiple job/node, floating licenses, database
            # scheduling, storage scheduling, should give each job
            # a resource request map.  This should be a list of dicts.
            # each dict should have a type
            # (node_shared|node_exclusive|license|db|storage) and
            # list of requirements.  For consumable cpus and memory,
            # use the initiatormap to generate one node dict for each
            # node of the initiatormap.  Add a list of consumable requests
            # for each task in that node dict.  If we ever support
            # database|storage, pull these out of the job comment and tack
            # these on as db dicts or storage dicts.  When the sized windows
            # are generated, get node resources for node dicts and db or
            # storage resources for db or storage dicts.
            # Should translate LoadL-specific names to generic names.
            # support only ConsumableCpus and ConsumableMemory, for now.
            resourcesreq = runjob_dict[job_step_id]['resourcesreq']
            #print "resourcesreq (%s)" % (resourcesreq,)
            consumable_list = string.split(resourcesreq,'+')
            cons_req = ''
            last_consumable = len(consumable_list) - 1
            resourcereq_dict = {'cpu' : 0, 'memory' : 0}
            if new_job_step['node_usage'] == 'node_shared' :
                node_dict_type = 'node_shared'
            else :
                node_dict_type = 'node_exclusive'
            for index in range(len(consumable_list)) :
                #print "consumable_list (%s)" % (consumable_list,)
                #(cons_name, cons_value) = string.split(consumable_list[index], '#cat_sep#')
                cons_tuple = string.split(consumable_list[index], '#cat_sep#')
                if len(cons_tuple) < 2 :
                    continue
                if cons_tuple[0] == 'ConsumableCpus' :
                    resourcereq_dict['cpu'] = long(cons_tuple[1])
                if cons_tuple[0] == 'ConsumableMemory' :
                    resourcereq_dict['memory'] = long(cons_tuple[1])
            #new_job_step['req_dict_list'] = [{
            #  'amount_int' : new_job_step['resource_amount_int'],
            #  'this_req_string' : new_job_step['cat_requirements_string']
            #   },
            #   ]
            #if new_job_step['state'] == 'Running' or new_job_step['state'] == 'Starting' :
            if new_job_step['state'] in ['Running', 'Starting', 'Preempted'] :
                if runjob_dict[job_step_id].has_key('taskinstancemachinemap') :
                    task_hosts = string.split(runjob_dict[job_step_id]['taskinstancemachinemap'], '+')
                    new_job_step['task_hosts'] = task_hosts
                if runjob_dict[job_step_id].has_key('machinemap') :
                    allocated_hosts = string.split(runjob_dict[job_step_id]['machinemap'], '+')
                    new_job_step['allocated_hosts'] = allocated_hosts
                else :
                    print "allocated_hosts not found for Running/Starting job"
                    job_string = ''
                    continue
                if runjob_dict[job_step_id].has_key('dispatchtime') :
                    new_job_step['Dispatch_Time'] = string.atof(runjob_dict[job_step_id]['dispatchtime'])
                else :
                    print "dispatchtime not found for Running/Starting job"
                    job_string = ''
                    continue
            # for preempted jobs, add on a requirement to run on
            # the allocated_hosts.  See if requirements has a Machine
            # requirement, if so, change it to the allocated_hosts.
            # if no Machine requirement, add one.
            if new_job_step['state'] == 'Preempted' :
                # (Machine == {"ds271" "ds272" "ds273"}) &&
                preempted_machines_list = copy.deepcopy(new_job_step['allocated_hosts'])
                quoted_preempted_machines_list = []
                for preempted_machine in preempted_machines_list :
                    preempted_machine = '"' + preempted_machine + '"'
                    #print "preempted_machine (%s)" % preempted_machine
                    quoted_preempted_machines_list.append(preempted_machine)
                # some funkiness here.  Lost the double-quotes when I
                # tried to add them in place, but it worked with a new list...
                #print "preempted_machine_list (%s)" % (preempted_machines_list,)
                #print "quoted_preempted_machine_list (%s)" % (quoted_preempted_machines_list,)
                preempted_machines_string = string.join(preempted_machines_list)
                quoted_preempted_machines_string = string.join(quoted_preempted_machines_list)
                #print "1. preempted_machines_string (%s)" % preempted_machines_string
                preempted_machines_string = "(Machine == {%s}) &&" % quoted_preempted_machines_string
                #print "2. preempted_machines_string (%s)" % preempted_machines_string
                restricted_req_string = new_job_step['requirements']
                restricted_req_string = machine_req_reo.sub('',restricted_req_string)
                #print "1. restricted_req_string (%s)" % restricted_req_string
                restricted_req_string = preempted_machines_string + ' ' + restricted_req_string
                #print "2. restricted_req_string (%s)" % restricted_req_string
                new_job_step['cat_requirements_string'] = get_requirements_string(restricted_req_string)
            else :
                new_job_step['cat_requirements_string'] = get_requirements_string(new_job_step['requirements'])
            resourcereq_dict_dict_list = []
            req_dict_list = []
            for resourcemap in resourcemap_list :
                resourcereq_dict_dict = {'type' : node_dict_type}
                req_list = []
                for index in range(long(resourcemap)) :
                    ## bug 549 fix ####
                    if new_job_step['node_usage'] == 'node_shared' :
                        if new_job_step['state'] in ['Running','Starting','Idle'] :
                            if resourcereq_dict['cpu'] == 0 :
                                #reset to 1, else it will break
                                resourcereq_dict['cpu'] = 1L
                                new_job_step['modified']='true'
                            if resourcereq_dict['memory'] == 0 :
                                #reset to 2 GB, else it will break
                                resourcereq_dict['memory'] = 2048L
                                new_job_step['modified']='true'
                     ## end bug 549 fix ##
                    req_list.append(resourcereq_dict)
                resourcereq_dict_dict['req_list'] = req_list
                resourcereq_dict_dict_list.append(resourcereq_dict_dict)

                req_dict_list.append(
                  { 'amount_int' : string.atoi(resourcemap),
                    'this_req_string' : new_job_step['cat_requirements_string']
                  }
                  )
            new_job_step['requested_resource_list'] = resourcereq_dict_dict_list
            new_job_step['req_dict_list'] = req_dict_list
        else :
            print "job_step_id (%s) not found in runjob_dict!" % \
            line_job_id
            continue
        # clear the old job_string, store the old new_job_step
        job_steps[new_job_step['name']] = new_job_step
    return job_steps
            
def get_resources_list() :
    if Catalina.SERVERMODE == 'SIM' and Catalina.QM_SIM != None :
        QUERYMACHINES = Catalina.QM_SIM
    else :
        QUERYMACHINES = Catalina.HOMEDIR + '/___QM_PLACEHOLDER___'
    machine_lines_list = os.popen(QUERYMACHINES).readlines()
    resources_dict = {}
    finished_reo = re.compile("^qm FINISHED$")
    finished_found = 0
    for line in machine_lines_list :
        try :
            finished_mo = finished_reo.match(line)
            if finished_mo != None :
                finished_found = 1
                raise 'Continue'
            elements_list = string.split(line, '#cat_delim#')
            dict = {}
            for element in elements_list :
                if element != '' :
                    name_value_list = string.split(element, ':')
                    if len(name_value_list) == 1 :
                        name_value_list.append('')
                    dict[name_value_list[0]] = string.strip(name_value_list[1])
            # Should check entire line, but for now, check for Machine
            if not dict.has_key('Machine') :
                raise 'Continue'
            resource_name = dict['Machine']
            #print "found line for Machine (%s)" % resource_name
            new_resource = initialize_resource(resource_name)
            new_resource['Machine'] = dict['Machine']
            new_resource['Arch'] =  dict['Arch']
            new_resource['OpSys'] =  dict['OpSys']
            new_resource['Disk'] =  string.atoi(dict['Disk'])
            new_resource['Pool'] =  string.atoi(dict['Pool'])
            class_instance_list = string.split(dict['ConfiguredClasses'], '+')
            new_resource['ConfiguredClasses_list'] = map(string.strip, class_instance_list)
            new_resource['AvailableClasses'] =  dict['AvailableClasses']
            class_instance_list = string.split(dict['AvailableClasses'], '+')
            available_classes_string = ''
            old_instance = class_instance_list[0]
            instance_counter = 1
            irange = range(len(class_instance_list))
            for i in irange :
                instance = class_instance_list[i]
                if instance != old_instance :
                    available_classes_string = available_classes_string + ("%s(%s)" % (old_instance, instance_counter - 1))
                    instance_counter = 1
                    old_instance = instance
                elif i == irange[-1] :
                    available_classes_string = available_classes_string + ("%s(%s)" % (old_instance, instance_counter))
                instance_counter = instance_counter + 1
            new_resource['AvailableClasses'] =  available_classes_string
            new_resource['Feature'] =  dict['Feature']
            if dict['Feature'] != '' :
                feature_string_list = string.split(dict['Feature'],'+')
            else :
                feature_string_list = []
            new_resource['properties_list'] = feature_string_list
            new_resource['Max_Starters'] =  string.atoi(dict['Max_Starters'])
            #new_resource['Memory'] =  string.atoi(dict['Memory'])
            #new_resource['Cpus'] =  string.atoi(dict['Cpus'])
            new_resource['State'] =  Catalina.RM_TO_CAT_RESOURCE_dict[dict['State']]
            new_resource['State_Change_Time'] = Catalina.Now_float
            # retrieve consumable cpu and memory, initial and available
            # values through the Data API.  The question here is, generate
            # a new_resource for each CPU and MB of memory, or let the
            # create_reservation routine in Catalina.py generate new
            # reservations for these.  To do new_resource here, would be
            # some overhead, whereas doing it in Catalina.py makes it less
            # portable...
            if dict.has_key('resourcesmap') and dict['resourcesmap'] != '' :
                for resource in string.split(dict['resourcesmap'], '+') :
                    resourcesmap_tuple = string.split(resource, '#cat_sep#')
                    if len(resourcesmap_tuple) < 3 :
                        print "Bad resourcesmap (%s)!" % resource
                        continue
                    resname, initialvalue, currentvalue = resourcesmap_tuple
                    if resname == 'ConsumableCpus' :
                        new_resource['ConsumableCpus'] = string.atoi(initialvalue)
                    if resname == 'ConsumableMemory' :
                        new_resource['ConsumableMemory'] = string.atoi(initialvalue)
            else :
                new_resource['ConsumableCpus'] = 0
                new_resource['ConsumableMemory'] = 0
            new_resource['Memory'] =  string.atoi(dict['Memory'])
            new_resource['Cpus'] =  string.atoi(dict['Cpus'])
            resources_dict[new_resource['Machine']] = new_resource
        except :
            #print "continuing for (%s)" % new_resource['name']
            #info_tuple = sys.exc_info()
            #print "(%s) (%s) (%s)" % info_tuple
            #info_list = ["%s" % info_tuple[0], "%s" % info_tuple[1], '\n']
            #traceback.print_tb(info_tuple[2])
            #tb_list = traceback.format_tb(info_tuple[2])
            #info_list = info_list + tb_list
            #tb_text = string.join(info_list)
            #message = tb_text
            #print "message (%s)" % message
            continue
    
    if Catalina.SERVERMODE == 'SIM' :
        LLSTATUS = Catalina.HOMEDIR + '/' + 'llstatus_sim'
    else :
        LLSTATUS = '/usr/lpp/LoadL/full/bin/llstatus -l | ___GREP_PLACEHOLDER___ -e Name -e Adapter'
    resources = []
    found_start = 0
    resource_string = ''
    resource_reo = re.compile( r"""^Name\s*=\s*(?P<Name>\S+).*$\n^Adapter\s*=\s*(?P<Adapter>.*)\s*$""", re.MULTILINE)
    name_adapter_list = resource_reo.findall(os.popen(LLSTATUS).read())
    for na_tuple in name_adapter_list : 
        if not resources_dict.has_key(na_tuple[0]) :
            #print "did not find (%s) in resources_dict" % na_tuple[0]
            continue
        resources_dict[na_tuple[0]]['Adapter'] = na_tuple[1]
    resources = resources_dict.values()
    if finished_found != 1 :
        raise 'IncompleteQM'
    return resources

def get_requirements_string(old_requirements_string) :
    # requirements line from getinitmap:
    # (Memory >= 4086) && (Machine == {"tf226i.sdsc.edu" "tf227i.sdsc.edu" "tf228i.sdsc.edu" }) && (Feature == "SDSC") && (Arch == "R6000") && (OpSys == "AIX43")
    # An expression could be constructed from this.  Substitute
    # "nodedict['Memory']" for Memory, substitute (nodedict['Name'] == "tf226i.sdsc.edu" or nodedict['Name'] == "tf227i.sdsc.edu" or nodedict['Name'] == "tf228i.sdsc.edu", etc.
    # Disk, Pool, Adapter not supported currently
    # check requirements
    # check adapter
    # check class
    # This is not bulletproof regex matching.  an os called 'MemoryOS' would
    # break the regex sub, for example...
    # should substitute Machine statement for standard boolean.
    # Machine == { "tf226i" "tf227i" "tf228i" } substituted to
    # (resource.get_Machine() == "tf226i.sdsc.edu") ||  
    # (resource.get_Machine() == "tf227i.sdsc.edu") ||
    # (resource.get_Machine() == "tf228i.sdsc.edu")
    # should substitute re.search(feature,resource.get_Feature())
    # Feature == "SDSC" substituted to
    # re.search(" SDSC ",resource.get_Feature())
    #print "starting with old_requirements_string (%s)" % old_requirements_string
    Memory_reo = re.compile(r"Memory")
    new_requirements_string = Memory_reo.sub(r"resource['Memory']", old_requirements_string)
    old_requirements_string = new_requirements_string
    #print "1. old_requirements_string (%s)" % old_requirements_string
    # for requirements like Machine == { "tf225i" "tf226i" "tf227i" }
    # need to handle separately
    Machine_list_reo = re.compile(r'Machine\s*(\S+)\s*\{(.*)\}')
    Machine_list_fo_list = Machine_list_reo.findall(old_requirements_string)
    if Machine_list_fo_list :
        for matched_tuple in Machine_list_fo_list :
            machine_list = string.split(string.strip(matched_tuple[1]))
            #machine_expression = '( '
            machine_expression = ''
            comparison = matched_tuple[0]
            for name_index in range(len(machine_list)) :
                machine_expression = machine_expression + "(resource['Machine'] %s %s)" % (comparison, machine_list[name_index])
                if name_index < len(machine_list) - 1 :
                    machine_expression = machine_expression + ' || '
                #print "machine_expression (%s)" % machine_expression
            #machine_expression = machine_expression[:-2]
            #machine_expression = machine_expression + ' )'
            new_requirements_string = Machine_list_reo.sub(machine_expression, old_requirements_string)
            old_requirements_string = new_requirements_string
            #print "1a. old_requirements_string (%s)" % old_requirements_string
    Machine_equate_reo = re.compile(r"Machine == \"")
    new_requirements_string = Machine_equate_reo.sub('resource[\'Machine\'] == "', old_requirements_string)
    old_requirements_string = new_requirements_string
    #print "2. old_requirements_string (%s)" % old_requirements_string
    # for feature requirements, need to handle separately
    Feature_reo = re.compile(r'Feature\s*==\s*"\s*(.*?)\s*"')
    #feature_expression = r"re.search(' \1 ',resource['Feature'])"
    feature_expression = r"re.search('\1',resource['Feature'])"
    new_requirements_string = Feature_reo.sub(feature_expression, old_requirements_string)
    old_requirements_string = new_requirements_string
    Arch_reo = re.compile(r"Arch")
    new_requirements_string = Arch_reo.sub(r"resource['Arch']", old_requirements_string)
    old_requirements_string = new_requirements_string
    OpSys_reo = re.compile(r"OpSys")
    new_requirements_string = OpSys_reo.sub(r"resource['OpSys']", old_requirements_string)
    old_requirements_string = new_requirements_string
    Disk_reo = re.compile(r"Disk")
    new_requirements_string = Disk_reo.sub(r"resource['Disk']", old_requirements_string)
    old_requirements_string = new_requirements_string
    Pool_reo = re.compile(r"Pool")
    new_requirements_string = Pool_reo.sub(r"resource['Pool']", old_requirements_string)
    old_requirements_string = new_requirements_string
    Tee_reo = re.compile(r"\(T\)")
    new_requirements_string = Tee_reo.sub(r"(1)", old_requirements_string)
    old_requirements_string = new_requirements_string
    and_reo = re.compile(r"&&")
    new_requirements_string = and_reo.sub(r'and', old_requirements_string)
    old_requirements_string = new_requirements_string
    or_reo = re.compile(r"\|\|")
    #print "old_requirements_string (%s)" % old_requirements_string
    new_requirements_string = or_reo.sub(r'or', old_requirements_string)
    #print "new_requirements_string (%s)" % new_requirements_string
    old_requirements_string = new_requirements_string
    return new_requirements_string

#def get_resource_dict_list(job_step, resources_db_handle) :
#    # This is not in get_job_steps, because resources may be
#    # updated independently from job_steps, and this routine
#    # is dependent on the resource_list
#    if job_step.has_key('resource_list') :
#        resource_list = job_step['resource_list']
#    else :
#        resource_list = get_resource_list(job_step, resources_db_handle)
#    this_resource_dict = {}
#    for resource in resource_list :
#        #this_resource_dict[resource['name']] = resource
#        this_resource_dict[resource['name']] = {}
#    resource_dict_list = [{
#      'amount_int' : job_step['resource_amount_int'],
#      'resource_dict' : this_resource_dict
#      },
#      ]
#    return resource_dict_list

def get_resource_dict_list(job_step, resources_db_handle) :
    # returns list of dict of amounts and resource objects that match job_step
    #print "start of get_resource_dict_list for (%s)" % job_step['name']
    if Catalina.DEBUGJOB != None and job_step['name'] == Catalina.DEBUGJOB :
        print "start of get_resource_dict_list for (%s)" % Catalina.DEBUGJOB
    if job_step.has_key('req_dict_list') and type(job_step['req_dict_list']) is types.ListType :
        req_dict_list = job_step['req_dict_list']
        if Catalina.DEBUGJOB != None and job_step['name'] == Catalina.DEBUGJOB :
            print "using req_dict_list (%s)" % req_dict_list
    else :
        if job_step.has_key('resource_amount_int') :
            amount_int = job_step['resource_amount_int']
        else :
            amount_int = None
        resource_list = [ {'amount_int' : amount_int, 'resource_dict' : resources_db_handle[0] }, ]
        if Catalina.DEBUGJOB != None and job_step['name'] == Catalina.DEBUGJOB :
            print "no req_dict_list!"
        return resource_list
    job_adapter_requirement = job_step['adapter']
    job_adapter_reo = re.compile(r"\((?P<interface>[\w\d]+),([\w\d]+),(?P<sharing>[\w\d]+),(?P<USorIP>[\w\d]+).*\)")
    job_adapter_mo = job_adapter_reo.match(job_adapter_requirement)
    if job_adapter_requirement == '' or job_adapter_mo.group('interface') in ['sn_single', 'sn_all'] :
        ready_adapter_match_string = ''
    else :
        ready_adapter_match_string = job_adapter_mo.group('interface') + \
          r'\(?\S+,(READY|)\)'
    screened_resource_list = []
    resources_shelf = resources_db_handle[0]
    this_resource_dict_list = []
    # LoadL only has one requirements spec for all nodes in the step, so
    # can get away with taking the requirements for the first node only...
    new_requirements_string = req_dict_list[0]['this_req_string']
    if new_requirements_string == '' :
        compiled_nrq = compile('1', '<string>', 'eval')
    else :
        try :
            compiled_nrq = compile(new_requirements_string, '<string>', 'eval')
        except :
            print "For job (%s) compile of requirements string failed (%s)!" % (job_step['name'], new_requirements_string)
            compiled_nrq = compile('0', '<string>', 'eval')
    nrq_matches = []
    #print "start of for loop for nrq_matches"
    for key in resources_shelf.keys() :
        if Catalina.DEBUGJOB != None and job_step['name'] == Catalina.DEBUGJOB :
            print "checking (%s)" % key
        to_be_continued = 0
        resource = resources_shelf[key]
        try :
            if not eval(compiled_nrq) :
                if Catalina.DEBUGJOB != None and job_step['name'] == Catalina.DEBUGJOB :
                    print "%s does not match" % key
                to_be_continued = 1
            else :
                if Catalina.DEBUGJOB != None and job_step['name'] == Catalina.DEBUGJOB :
                    print "%s matches" % key
        except NameError :
            print "NameError Bad requirements string(%s) for job (%s)!" % (job_step['requirements'], job_step['name'])
            print "resource (%s)" % resource
            continue
        except KeyError :
            print "KeyError Bad requirements string(%s) for job (%s)!" % (job_step['requirements'], job_step['name'])
            continue
        if to_be_continued == 1 :
            if Catalina.DEBUGJOB != None and job_step['name'] == Catalina.DEBUGJOB :
                print "to_be_continued == 1 for (%s)" % resource['name']
            continue
        if Catalina.DEBUGJOB != None and job_step['name'] == Catalina.DEBUGJOB :
            print "passed to_be_continued test (%s)" % resource['name']
        nrq_matches.append(key)
    #print "start of for loop over req_dict_list"
    for req_dict in req_dict_list :
        job_initiator_per_node_int = req_dict['amount_int']
        resource_dict = {}
        #resource_dict['amount_int'] = req_dict['amount_int']
        resource_dict['amount_int'] = 1
        resource = None
        #new_requirements_string = req_dict['this_req_string']
        #if new_requirements_string == '' :
        #    compiled_nrq = compile('1', '<string>', 'eval')
        #else :
        #    compiled_nrq = compile(new_requirements_string, '<string>', 'eval')
        #if Catalina.DEBUGJOB != None and job_step['name'] == Catalina.DEBUGJOB :
        #    print "using new_requirements_string (%s)" % new_requirements_string
        this_resource_dict = {}

        #print "before for loop over resources"
        for key in resources_shelf.keys() :
            #print ".",
            resource = resources_shelf[key]
            if not key in nrq_matches :
                continue
            job_class_requirement = job_step['job_class']
            #step_initiatormap = job_step['initiatormap']
            #initiators_list = string.split(step_initiatormap, '+')
            #job_initiator_per_node_int = 0
            #for initiator in initiators_list :
            #    if string.atoi(initiator) > job_initiator_per_node_int :
            #        job_initiator_per_node_int = string.atoi(initiator)
            # Right here, need to check for number of ConfiguredClasses
            # This may also be the place to implement mult-job per node
            # by reserving Class initiators...
            if not resource.has_key('ConfiguredClasses_list') or resource['ConfiguredClasses_list'] == None :
                if Catalina.DEBUGJOB != None and job_step['name'] == Catalina.DEBUGJOB :
                    print "no ConfiguredClasses_list"
                continue
            if Catalina.DEBUGJOB != None and job_step['name'] == Catalina.DEBUGJOB :
                print "passed ConfiguredClass test"
            matched_classes_list = []
            for prospective_class in resource['ConfiguredClasses_list'] :
                if prospective_class == job_class_requirement :
                    matched_classes_list.append(prospective_class)
            #matched_classes_list = filter(lambda x, job_class_requirement=job_class_requirement : \
            #  job_class_requirement == x, resource['ConfiguredClasses_list'])
            if len(matched_classes_list) == 0 :
                # resource does not have this class at all
                if Catalina.DEBUGJOB != None and job_step['name'] == Catalina.DEBUGJOB :
                    print "no class match (%s)" % (matched_classes_list,)
                continue
            elif len(matched_classes_list) < job_initiator_per_node_int :
                # The resource has the class, but fewer initiators for that
                # class than the job needs.
                if Catalina.DEBUGJOB != None and job_step['name'] == Catalina.DEBUGJOB :
                    print "too few classes (%s)" % job_initiator_per_node_int
                continue
            if Catalina.DEBUGJOB != None and job_step['name'] == Catalina.DEBUGJOB :
                print "passed match class test"
            if resource['Adapter'] == None or not re.search(ready_adapter_match_string, resource['Adapter']) :
                if Catalina.DEBUGJOB != None and job_step['name'] == Catalina.DEBUGJOB :
                    print "Adapter mismatch for (%s)!" % resource['name']
                    print "%s %s" % (resource['Adapter'], ready_adapter_match_string)
                continue
            if Catalina.DEBUGJOB != None and job_step['name'] == Catalina.DEBUGJOB :
                print "passed adapter class test"
            #if to_be_continued == 1 :
            #    continue
            #if Catalina.DEBUGJOB != None and job_step['name'] == Catalina.DEBUGJOB :
            #    print "passed to_be_continued test"
            this_resource_dict[resource['name']] = {}
        #print "after for loop over resources"
        resource_dict['resource_dict'] = this_resource_dict
        if Catalina.DEBUGJOB != None and job_step['name'] == Catalina.DEBUGJOB :
            print "adding (%s)" % (this_resource_dict.keys(),)
        this_resource_dict_list.append(resource_dict)
    if Catalina.DEBUGJOB != None and job_step['name'] == Catalina.DEBUGJOB :
        print "this_resource_dict_list (%s)" % (this_resource_dict_list,)
    #print "after for loop over req_dict_list"
    return this_resource_dict_list
    
def get_resource_name_list(resource_list) :
    names = []
    for resource in resource_list :
        names.append(resource['name'])
    return names

def run_jobs(events_db_handle, jobs_db_handle, resources_db_handle, reservations_db_handle) :
    #start_job_returncode_reo = start_job_returncode_reo
    RUNJOB='___RUNJOB_PLACEHOLDER___'
    print "in run_jobs"
    RUNJOB = Catalina.HOMEDIR + '/' + RUNJOB
    RESUMEJOB='___RESUMEJOB_PLACEHOLDER___'
    # all dbs can be read
    jobs_dict = jobs_db_handle[0]
    resources_dict = resources_db_handle[0]
    reservations_dict = reservations_db_handle[0]
    jobs_to_run = {}
    for reservation in reservations_dict.values() :
        #print "doing reservation (%s) with purpose_type_string (%s)" % (reservation['name'], reservation['purpose_type_string'])
        if not reservation['purpose_type_string'] in ['job', 'preempted_job'] :
            #print "skipping reservation (%s) with purpose_type_string (%s)" % (reservation['name'], reservation['purpose_type_string'])
            continue
        start_time_float = reservation['start_time_float']
        if (Catalina.Now_float + 1) >= start_time_float and (Catalina.Now_float - start_time_float) <= Catalina.FUDGE_FACTOR/2 :
            if reservation.has_key('start_count_int') and \
              reservation['start_count_int'] >= 1 :
                continue
            job_stepid = reservation['job_runID']
            if not jobs_dict[job_stepid]['state'] in ['Idle', 'Preempted'] :
                continue
            node_list = copy.deepcopy(reservation['node_list'])
            #node_list.reverse()
            fromhost = jobs_dict[job_stepid]['fromhost']
            cluster = jobs_dict[job_stepid]['cluster']
            proc = jobs_dict[job_stepid]['proc']
            initiatormap = jobs_dict[job_stepid]['initiatormap']
            resourcemap_list = string.split(initiatormap,'+')
            resourcemap_string = ''
            #resourcemap_list.reverse()
            for i in range(len(resourcemap_list)) :
                for j in range(string.atoi(resourcemap_list[i])) :
                    resourcemap_string = resourcemap_string + ' ' + \
                        node_list[i]
            
            # Added by Martin W. Margo (6/29/2006), abbreviated form
            resourcemap_string  = \
                Catalina.convertToAbbreviatedForm(resourcemap_string.lstrip(" "))
            
            
            if jobs_dict[job_stepid]['state'] == 'Preempted' :
                runstring = ' ' + fromhost + ' ' + cluster + ' ' + proc
            else :
                runstring = ' ' + fromhost + ' ' + cluster + ' ' + proc + \
                    ' ' + resourcemap_string
            jobs_to_run[job_stepid] = (runstring, reservation)
    print "len(jobs_to_run.keys()) is (%s)" % len(jobs_to_run.keys())
    for job in jobs_to_run.keys() :
        run_string = jobs_to_run[job][0]
        reservation = jobs_to_run[job][1]
        return_string = None
        #if jobs_dict[job]['state'] == 'Preempted' :
        #    cmd = Catalina.PREEMPTCMD + ' ' + job + ' RESUME_STEP'
        #else :
        #    cmd = RUNJOB + ' ' + run_string
        if jobs_dict[job]['state'] == 'Preempted' :
            cmd = RESUMEJOB + ' ' + job
            if Catalina.SERVERMODE == 'NORMAL' :
                return_string = os.popen(cmd).readlines()
                print return_string
            else :
                print "would run (%s)" % cmd
        cmd = RUNJOB + ' ' + run_string
        if Catalina.SERVERMODE == 'NORMAL' :
            print "really running job..."
            return_string = os.popen(cmd).readlines()
            print return_string
        else :
            return_string = \
              [
              'adding to nodelist (tf183i)\012',
              'adding to nodelist (tf183i)\012',
              'adding to nodelist (tf184i)\012',
              'adding to nodelist (tf184i)\012',
              'rc from ll_start_job is >0<\012'
              ]
            print "%s" % cmd
        if return_string != None :
            joined_return_string = string.join(return_string,'\n')
            start_job_returncode_mo = start_job_returncode_reo.search(joined_return_string)
        if start_job_returncode_mo != None :
            if start_job_returncode_mo.groupdict().has_key('code') :
                return_code_int = string.atoi(start_job_returncode_mo.group('code'))
                print "return_code_int is (%s)" % return_code_int
                if return_code_int == 0 :
                    Catalina.update_object_attribute(
                      'start_count_int',
                      1,
                      reservation,
                      reservations_db_handle)
                    print "setting start_count_int to (%s) for (%s)" % \
                      (1, reservation['job_runID'])
            else :
                print "no 'code' group found"
        else :
            print "start_job_returncode_mo == None"
        event = {
          'name' : 'run_jobs',
          'cmd' : cmd,
          'return_string' : return_string
          }
        Catalina.log_event(event, events_db_handle)
            

def get_configured_resources_list(resources_db_handle) :
    def strip_newline(line) :
        stripped_line = line[:-1]
        return stripped_line
    cmd_string = '___CAT_PLACEHOLDER___ ' + Catalina.LOADL_ADMIN_FILE + " | ___GREP_PLACEHOLDER___ 'type = machine' | ___GREP_PLACEHOLDER___ -v default | ___GREP_PLACEHOLDER___ -v ^# | ___AWK_PLACEHOLDER___ -F: '{print $1}'"
    lines = os.popen(cmd_string).readlines()
    stripped_lines = map(strip_newline, lines)
    configured_resources_list = map( initialize_resource, stripped_lines)
    return configured_resources_list
@


1.71
log
@remove resourcemap_list.reverse(), to be consistent with new
non-reversing qj_LL
@
text
@d41 1
d977 1
a977 1
            node_list.reverse()
@


1.70
log
@resourcemap_list.reverse() to compensate for reversed initiatormap
@
text
@d446 1
a446 1
            resourcemap_list.reverse()
d983 1
a983 1
            resourcemap_list.reverse()
@


1.69
log
@fix typo in email message, related to bug 549
it says it will set the memory to 3 GB while in fact it will set it to 2 GB
mmargo
@
text
@d284 1
a284 1
and/or 2GB of RAM per task. 
d445 2
@


1.68
log
@add speculative_state attribute to resource
@
text
@d284 1
a284 1
and/or 3GB of RAM per task. 
@


1.67
log
@fix bug 549 for good
mmargo
@
text
@d72 1
d797 3
a799 3
    #if Catalina.DEBUGJOB != None and job_step['name'] == Catalina.DEBUGJOB :
    #    print "start of get_resource_dict_list for (%s)" % Catalina.DEBUGJOB
    #print "start of get_resource_dict_list"
d938 2
@


1.66
log
@fix bug 549
mmargo
@
text
@d273 4
a276 7
        if job.has_key('node_usage') and job['node_usage'] == 'node_shared' :
            
            ## notified is artificial field set on the job database. 
            if not job.has_key('notified') :
                # check if the consumable cpu and memory are correctly requested
                if job.has_key('requested_resource_list') :
                    notify=0
d278 3
a280 16
                    ## all the resources are identical, no use to iterate all keys
                    req_cpu = job['requested_resource_list'][0]['req_list'][0]['cpu']
                    req_mem = job['requested_resource_list'][0]['req_list'][0]['memory']
                    if req_cpu == 0 :
                        ## reset it to 1L
                        notify=1
                        job['requested_resource_list'][0]['req_list'][0]['cpu'] = 1L
                    if req_mem == 0 :
                        ## reset it to 3GB
                        notify=1
                        job['requested_resource_list'][0]['req_list'][0]['memory'] = 3072L
                            
                    if notify :
                        recipient = Catalina.MAIL_RECIPIENT + ' ' + job['user']
                        subject = 'Unrecognized consumable resources. Reset to default'
                        message = """
d287 1
a287 5
                        Catalina.warn(message,subject,recipient)
                      
                        ## add this to the job database
                        job['notified']=''
                      
d289 12
d546 12
@


1.65
log
@fix lstrip()
does not accept an emtpy string
mmargo
@
text
@d272 39
d982 1
a982 1
                Catalina.convertToAbbreviatedForm(resourcemap_string.lstrip())
@


1.64
log
@Change the runjob() to call Catalina.AddShorthandNotation() to send the proper shorthand to rj_LL
mmargo
@
text
@d943 1
a943 1
                Catalina.convertToAbbreviatedForm(resourcemap_string.lstrip(" "))
@


1.63
log
@Modify cancel_job() to accept optional parameter messages
Martin W.Margo
@
text
@d940 6
@


1.62
log
@took out PREEMPT_STEP and RESUME_STEP
@
text
@d149 5
a153 1
def cancel_job(job_step, events_db_handle) :
@


1.61
log
@ll_preempt as well as ll_start_job to resume
@
text
@d169 2
a170 1
    cmd_string = PREEMPTJOB + ' ' + job_step['name'] + ' PREEMPT_STEP'
d952 1
a952 1
            cmd = RESUMEJOB + ' ' + job + ' RESUME_STEP'
@


1.60
log
@PREEMPTJOB
@
text
@d903 1
d950 7
@


1.59
log
@change preempt and resume commands
@
text
@d168 2
a169 1
    cmd_string = Catalina.PREEMPTCMD + ' ' + job_step['name'] + ' PREEMPT_STEP'
@


1.58
log
@add preemption
@
text
@d168 2
a169 2
    cmd_string = Catalina.PREEMPTCMD + ' ' + job_step['name']
    output = 'llpreempt: Preempt command has been sent to the central manager.'
d172 3
a174 3
        mo = re.match(output, return_string)
        if mo == None :
            raise 'PreemptJobFailure', job_step
d944 4
@


1.57
log
@put exception handling around compiled_nrq, to catch broken requirements
string
@
text
@d34 1
d84 1
d104 2
d167 18
d297 4
a347 1
            new_job_step['cat_requirements_string'] = get_requirements_string(new_job_step['requirements'])
d356 2
d370 14
a450 17
            resourcereq_dict_dict_list = []
            req_dict_list = []
            for resourcemap in resourcemap_list :
                resourcereq_dict_dict = {'type' : node_dict_type}
                req_list = []
                for index in range(long(resourcemap)) :
                    req_list.append(resourcereq_dict)
                resourcereq_dict_dict['req_list'] = req_list
                resourcereq_dict_dict_list.append(resourcereq_dict_dict)

                req_dict_list.append(
                  { 'amount_int' : string.atoi(resourcemap),
                    'this_req_string' : new_job_step['cat_requirements_string']
                  }
                  )
            new_job_step['requested_resource_list'] = resourcereq_dict_dict_list
            new_job_step['req_dict_list'] = req_dict_list
d456 2
a457 1
            if new_job_step['state'] == 'Running' or new_job_step['state'] == 'Starting' :
d474 46
d666 1
d670 1
d678 2
a679 1
            machine_expression = '( '
d681 7
a687 4
            for name in machine_list :
                machine_expression = machine_expression + "(resource['Machine'] %s %s) ||" % (comparison, name)
            machine_expression = machine_expression[:-2]
            machine_expression = machine_expression + ' )'
d690 1
d694 1
d720 1
d722 1
d908 3
a910 1
        if reservation['purpose_type_string'] != 'job' :
d918 1
a918 1
            if jobs_dict[job_stepid]['state'] != 'Idle' :
d933 5
a937 2
            runstring = ' ' + fromhost + ' ' + cluster + ' ' + proc + \
                ' ' + resourcemap_string
@


1.56
log
@reversed node_list
@
text
@d699 5
a703 1
        compiled_nrq = compile(new_requirements_string, '<string>', 'eval')
@


1.55
log
@removed gmtime
@
text
@d20 1
d722 6
d793 4
a796 4
            if to_be_continued == 1 :
                continue
            if Catalina.DEBUGJOB != None and job_step['name'] == Catalina.DEBUGJOB :
                print "passed to_be_continued test"
d833 2
a834 1
            node_list = reservation['node_list']
@


1.54
log
@change a filter/lambda to for loop in get_resource_dict_list
@
text
@d190 1
a190 1
(time.asctime(time.gmtime(Catalina.Now_float)), job['name'],
d233 1
a233 1
(time.asctime(time.gmtime(Catalina.Now_float)), job['name'],
@


1.53
log
@remove get_resource_list, only check node requirements once per job
@
text
@d667 1
d700 1
d722 1
d738 1
d740 1
d760 6
a765 2
            matched_classes_list = filter(lambda x, job_class_requirement=job_class_requirement : \
              job_class_requirement == x, resource['ConfiguredClasses_list'])
d791 1
d796 1
@


1.52
log
@resource_amount_int to initialize_jobs
@
text
@d698 22
d734 1
a735 3
            if Catalina.DEBUGJOB != None and job_step['name'] == Catalina.DEBUGJOB :
                print "checking (%s)" % key
            to_be_continued = 0
d737 1
a737 11
            try :
                if not eval(compiled_nrq) :
                    if Catalina.DEBUGJOB != None and job_step['name'] == Catalina.DEBUGJOB :
                        print "%s does not match" % key
                    to_be_continued = 1
                else :
                    if Catalina.DEBUGJOB != None and job_step['name'] == Catalina.DEBUGJOB :
                        print "%s matches" % key
            except NameError :
                print "NameError Bad requirements string(%s) for job (%s)!" % (job_step['requirements'], job_step['name'])
                print "resource (%s)" % resource
a738 4
            except KeyError :
                print "KeyError Bad requirements string(%s) for job (%s)!" % (job_step['requirements'], job_step['name'])
                continue

a787 80
def get_resource_list(job_step, resources_db_handle) :
    # returns list of resource objects that match job_step
    screened_resource_list = []
    job_adapter_requirement = job_step['adapter']
    job_adapter_reo = re.compile(r"\((?P<interface>[\w\d]+),([\w\d]+),(?P<sharing>[\w\d]+),(?P<USorIP>[\w\d]+).*\)")
    job_adapter_mo = job_adapter_reo.match(job_adapter_requirement)
    if job_adapter_requirement == '' or job_adapter_mo.group('interface') in ['sn_single', 'sn_all'] :
        ready_adapter_match_string = ''
    else :
        ready_adapter_match_string = job_adapter_mo.group('interface') + \
          r'\(?\S+,(READY|)\)'
    # The following depends on ConfiguredClasses being in the form of
    # llstatus -l ConfiguredClasses:
    # ConfiguredClasses   = Diag9(8) Diag0(8) standby(8) low(8) normal(16) high(8)
    # rewrite for Data Access API where class names are repeated for each
    # instance of class
    job_class_requirement = job_step['job_class']
    #job_class_search_string = r"%s\((?P<class_amount>\d+)\)" % job_class_requirement
    #job_class_reo = re.compile(job_class_search_string)
    # Find the number of initiators per node, assuming a rectangular
    # geometry.  Take the largest in the map.
    # Can no longer assume a rectangular geometry.  Should also deal
    # with class initiators...
    step_initiatormap = job_step['initiatormap']
    initiators_list = string.split(step_initiatormap, '+')
    job_initiator_per_node_int = 0
    for initiator in initiators_list :
        if string.atoi(initiator) > job_initiator_per_node_int :
            job_initiator_per_node_int = string.atoi(initiator)
    resources_shelf = resources_db_handle[0]
    # slow point
    if job_step.has_key('cat_requirements_string') :
        new_requirements_string = job_step['cat_requirements_string']
    else :
        new_requirements_string = get_requirements_string(job_step['requirements'])
    if new_requirements_string == '' :
        compiled_nrq = compile('1', '<string>', 'eval')
    else :
        compiled_nrq = compile(new_requirements_string, '<string>', 'eval')
    if Catalina.DEBUGJOB != None and job_step['name'] == Catalina.DEBUGJOB :
        print "new_requirements_string (%s)" % new_requirements_string
    for key in resources_shelf.keys() :
        to_be_continued = 0
        resource = resources_shelf[key]
        if Catalina.DEBUGJOB != None and job_step['name'] == Catalina.DEBUGJOB :
            print "resource['Feature'] (%s)" % resource['Feature']
        try :
            if not eval(compiled_nrq) :
                if Catalina.DEBUGJOB != None and job_step['name'] == Catalina.DEBUGJOB :
                    print "%s does not match" % key
                to_be_continued = 1
            else :
                if Catalina.DEBUGJOB != None and job_step['name'] == Catalina.DEBUGJOB :
                    print "%s matches" % key
        except NameError :
            print "Bad requirements string(%s) for job (%s)!" % (job_step['requirements'], job_step['name'])
            break
        if to_be_continued == 1 :
            continue
        # Right here, need to check for number of ConfiguredClasses
        # This may also be the place to implement mult-job per node
        # by reserving Class initiators...
        if not resource.has_key('ConfiguredClasses_list') or resource['ConfiguredClasses_list'] == None :
            continue
        matched_classes_list = filter(lambda x, job_class_requirement=job_class_requirement : \
          job_class_requirement == x, resource['ConfiguredClasses_list'])
        if len(matched_classes_list) == 0 :
            # resource does not have this class at all
            continue
        #elif len(matched_classes_list) < job_initiator_per_node_int :
        #    # The resource has the class, but fewer initiators for that
        #    # class than the job needs.
        #    continue
        if resource['Adapter'] == None or not re.search(ready_adapter_match_string, resource['Adapter']) :
            print "Adapter mismatch for (%s)!" % resource['name']
            print "%s %s" % (resource['Adapter'], ready_adapter_match_string)
            continue
        screened_resource_list.append(resource)
    return screened_resource_list

@


1.51
log
@update all attributes of configured resources
@
text
@d99 1
@


1.50
log
@took HOMEDIR out of QUERYMACHINES for SIM
@
text
@d54 1
a54 2
    new_resource['Disk'] = None
    new_resource['Feature'] = None
d65 4
a68 4
    new_resource['Memory'] = None
    new_resource['Cpus'] = None
    new_resource['ConsumableMemory'] = None
    new_resource['ConsumableCpus'] = None
@


1.49
log
@add job_class to list of job attributes that get updated
@
text
@d458 1
a458 1
        QUERYMACHINES = Catalina.HOMEDIR + '/' + Catalina.QM_SIM
@


1.48
log
@SIM changes
@
text
@d31 1
@


1.47
log
@validate QOS
@
text
@d45 1
a45 1
        Now_float = float(os.system(TIME_SIM))
d108 1
a108 1
        cmd = Catalina.HOMEDIR + '/' + Catalina.QJ_SIM
@


1.46
log
@delimiter for Catalina_res_bind changed to ','
initialize_resource puts empty list in for classes and properties lists
only do requirements string check for first node
@
text
@d343 6
a348 1
                        new_job_step['QOS'] =  QOS
@


1.45
log
@change class tests
put 1 in amount_int for each element of resource_dict_list
@
text
@d87 3
d337 1
a337 1
                        raw_res_ids = string.split(fields[1], ':')
d674 8
d685 7
a696 1
        new_requirements_string = req_dict['this_req_string']
d698 5
a702 4
        if new_requirements_string == '' :
            compiled_nrq = compile('1', '<string>', 'eval')
        else :
            compiled_nrq = compile(new_requirements_string, '<string>', 'eval')
a726 8
            job_adapter_requirement = job_step['adapter']
            job_adapter_reo = re.compile(r"\((?P<interface>[\w\d]+),([\w\d]+),(?P<sharing>[\w\d]+),(?P<USorIP>[\w\d]+).*\)")
            job_adapter_mo = job_adapter_reo.match(job_adapter_requirement)
            if job_adapter_requirement == '' or job_adapter_mo.group('interface') in ['sn_single', 'sn_all'] :
                ready_adapter_match_string = ''
            else :
                ready_adapter_match_string = job_adapter_mo.group('interface') + \
                  r'\(?\S+,(READY|)\)'
@


1.44
log
@added class, initiator count, adapter restrictions to get_resourced_dict_list
@
text
@d37 1
d656 2
d660 2
d668 2
d675 1
d677 2
a678 1
        resource_dict['amount_int'] = req_dict['amount_int']
d685 2
d689 2
d695 2
d698 3
d718 6
a723 6
            step_initiatormap = job_step['initiatormap']
            initiators_list = string.split(step_initiatormap, '+')
            job_initiator_per_node_int = 0
            for initiator in initiators_list :
                if string.atoi(initiator) > job_initiator_per_node_int :
                    job_initiator_per_node_int = string.atoi(initiator)
d728 2
d731 2
d737 2
d743 2
d746 2
d749 3
a751 2
                print "Adapter mismatch for (%s)!" % resource['name']
                print "%s %s" % (resource['Adapter'], ready_adapter_match_string)
d753 2
a754 1

d757 2
d761 2
@


1.43
log
@support multireq jobs
@
text
@d690 35
@


1.42
log
@remove check for number of initiators for accepted resources
@
text
@d400 1
d408 6
d415 1
d634 19
d654 3
a656 5
    # This is not in get_job_steps, because resources may be
    # updated independently from job_steps, and this routine
    # is dependent on the resource_list
    if job_step.has_key('resource_list') :
        resource_list = job_step['resource_list']
d658 38
a695 11
        resource_list = get_resource_list(job_step, resources_db_handle)
    this_resource_dict = {}
    for resource in resource_list :
        #this_resource_dict[resource['name']] = resource
        this_resource_dict[resource['name']] = {}
    resource_dict_list = [{
      'amount_int' : job_step['resource_amount_int'],
      'resource_dict' : this_resource_dict
      },
      ]
    return resource_dict_list
@


1.41
log
@if sn_single or sn_all, bail on adapter matching
@
text
@d666 2
d714 4
a717 4
        elif len(matched_classes_list) < job_initiator_per_node_int :
            # The resource has the class, but fewer initiators for that
            # class than the job needs.
            continue
@


1.40
log
@ignore adapter req, if sn_single
@
text
@d651 1
a651 1
    if job_adapter_requirement == '' or job_adapter_requirement == 'sn_single' :
@


1.39
log
@smp
@
text
@d62 1
d491 5
d651 1
a651 1
    if job_adapter_requirement == '' :
@


1.38
log
@added continue, if job not found in runjob_dict
@
text
@d25 1
d33 1
d36 1
d65 2
d69 1
a323 14
            if new_job_step['state'] == 'Running' or new_job_step['state'] == 'Starting' :
                if runjob_dict[job_step_id].has_key('machinemap') :
                    allocated_hosts = string.split(runjob_dict[job_step_id]['machinemap'], '+')
                    new_job_step['allocated_hosts'] = allocated_hosts
                else :
                    print "allocated_hosts not found for Running/Starting job"
                    job_string = ''
                    continue
                if runjob_dict[job_step_id].has_key('dispatchtime') :
                    new_job_step['Dispatch_Time'] = string.atof(runjob_dict[job_step_id]['dispatchtime'])
                else :
                    print "dispatchtime not found for Running/Starting job"
                    job_string = ''
                    continue
d354 8
d363 44
d412 17
d464 1
d491 25
a517 2
            new_resource['State'] =  Catalina.RM_TO_CAT_RESOURCE_dict[dict['State']]
            new_resource['State_Change_Time'] = Catalina.Now_float
d520 10
d542 3
d621 3
d630 2
a631 1
        this_resource_dict[resource['name']] = resource
@


1.37
log
@simpler Adapter Req parsing
@
text
@d371 1
@


1.36
log
@changed adapter requirements to simpler expression search
@
text
@d252 1
a252 1
        LLQ = '/usr/lpp/LoadL/full/bin/llq -l | /usr/bin/grep -e "Job Step Id" -e Specify -e "Adapter Requirement"'
d257 42
a298 19
    matchstr = re.compile( r"""(^\s*Job\ Step\ Id:\ (?P<job_step_id>\S+))
             (.*)
             (^\s*Adapter\ Requirement:\ ?(?P<adapter>\S*)$)"""
        ,re.MULTILINE | re.DOTALL | re.VERBOSE)
    for line in os.popen(LLQ).readlines() :
        job_string = job_string + line
        line_so = None
        line_so = re.search(r"^llq: Specify -x option in addition to -l option to obtain Task Instance information.", line)
        if line_so != None :
            # parse the job_string, setting values in new_job_step
            match_object = matchstr.search(job_string)
            if match_object == None :
                print "Job llq match failed!"
                message = "llq match failure for (%s)" % first_string
                subject = "llq match failure for %s"
                recipient = Catalina.MAIL_RECIPIENT
                Catalina.warn(message, subject, recipient)
            elif not runjob_dict.has_key(match_object.group('job_step_id')) :
                print "runjob_dict does not have (%s)" % match_object.group('job_step_id')
d300 22
a321 98
                llq_job_step_name = match_object.group('job_step_id')
                llq_job_step_adapter = match_object.group('adapter')
                if runjob_dict.has_key(match_object.group('job_step_id')) :
                    required_keys_tuple = (
                      'user',
                      'class',
                      'wall_clock_limit',
                      'account',
                      'group',
                      'requirementsmap',
                      'state',
                      'initiatormap',
                      'fromhost',
                      'cluster',
                      'comment',
                      'proc',
                      'submittime'
                      )
                    job_step_id = match_object.group('job_step_id')
                    present_keys_list = runjob_dict[job_step_id].keys()
                    for required_key in required_keys_tuple :
                        if required_key not in present_keys_list :
                            print "required key (%s) not found" % required_key
                            job_string = ''
                            continue
                    new_job_step = initialize_job_step(job_step_id)
                    new_job_step['user'] = runjob_dict[job_step_id]['user']
                    if Catalina.RM_TO_CAT_JOB_dict.has_key(runjob_dict[job_step_id]['state']) :
                        new_job_step['state'] = Catalina.RM_TO_CAT_JOB_dict[runjob_dict[job_step_id]['state']]
                    else :
                        new_job_step['state'] = 'Unknown'
                    new_job_step['job_class'] = runjob_dict[job_step_id]['class']
                    new_job_step['wall_clock_limit'] = string.atof(runjob_dict[job_step_id]['wall_clock_limit'])
                    new_job_step['account'] = runjob_dict[job_step_id]['account']
                    new_job_step['group'] = runjob_dict[job_step_id]['group']
                    requirements_map = runjob_dict[job_step_id]['requirementsmap']
                    single_requirements_list = string.split(requirements_map, '+')
                    new_job_step['requirements'] = single_requirements_list[0]
                    new_job_step['adapter'] = llq_job_step_adapter
                    new_job_step['cat_requirements_string'] = get_requirements_string(new_job_step['requirements'])
                    new_job_step['fromhost'] = runjob_dict[job_step_id]['fromhost']
                    new_job_step['cluster'] = runjob_dict[job_step_id]['cluster']
                    new_job_step['proc'] = runjob_dict[job_step_id]['proc']
                    new_job_step['SubmitTime'] = string.atof(runjob_dict[job_step_id]['submittime'])
                    if runjob_dict[job_step_id].has_key('dispatchtime') :
                        new_job_step['Dispatch_Time'] = string.atof(runjob_dict[job_step_id]['dispatchtime'])
                    if runjob_dict[job_step_id].has_key('completiontime') :
                        new_job_step['completion_time'] = string.atof(runjob_dict[job_step_id]['completiontime'])
                    if new_job_step['state'] == 'Running' or new_job_step['state'] == 'Starting' :
                        if runjob_dict[job_step_id].has_key('machinemap') :
                            allocated_hosts = string.split(runjob_dict[job_step_id]['machinemap'], '+')
                            new_job_step['allocated_hosts'] = allocated_hosts
                        else :
                            print "allocated_hosts not found for Running/Starting job"
                            job_string = ''
                            continue
                        if runjob_dict[job_step_id].has_key('dispatchtime') :
                            new_job_step['Dispatch_Time'] = string.atof(runjob_dict[job_step_id]['dispatchtime'])
                        else :
                            print "dispatchtime not found for Running/Starting job"
                            job_string = ''
                            continue
                    if runjob_dict[job_step_id].has_key('comment') :
                        new_job_step['comment'] = runjob_dict[job_step_id]['comment']
                        elements = string.split(runjob_dict[job_step_id]['comment'], ';')
                        for element in elements :
                            string.strip(element)
                            fields = string.split(element, '=')
                            if string.strip(fields[0]) == 'Catalina_res_bind' :
                                res_ids_list = []
                                raw_res_ids = string.split(fields[1], ':')
                                for id in raw_res_ids :
                                    res_ids_list.append(string.strip(id))
                                new_job_step['reservation_binding'] =  res_ids_list
                            elif string.strip(fields[0]) == 'QOS' :
                                QOS = string.strip(fields[1])
                                new_job_step['QOS'] =  QOS
                            elif string.strip(fields[0]) == 'Catalina_local_admin_priority' :
                                local_admin_priority_string = string.strip(fields[1])
                                new_job_step['local_admin_priority_string'] = local_admin_priority_string
                            elif string.strip(fields[0]) == 'Catalina_local_user_priority' :
                                local_user_priority_string = string.strip(fields[1])
                                new_job_step['local_user_priority_string'] = local_user_priority_string
                            elif string.strip(fields[0]) == 'Catalina_run_at_risk' :
                                run_at_risk_string = string.strip(fields[1])
                                #print "fromhost, proc, cluster (%s, %s, %s)" % \
                                #  (new_job_step['fromhost'], new_job_step['proc'], new_job_step['cluster'])
                                #print "run_at_risk_string (%s)" % run_at_risk_string
                                if run_at_risk_string in ['Yes','YES','yes','Y','y','1'] :
                                    new_job_step['run_at_risk_int'] = 1
                    new_job_step['initiatormap'] = runjob_dict[job_step_id]['initiatormap']
                    resourcemap_list = string.split(new_job_step['initiatormap'], '+')
                    new_job_step['resource_amount_int'] = len(resourcemap_list)
                    #new_job_step['req_dict_list'] = [{
                    #  'amount_int' : new_job_step['resource_amount_int'],
                    #  'this_req_string' : new_job_step['cat_requirements_string']
                    #   },
                    #   ]
d323 50
a372 5
                    print "job_step_id (%s) not found in runjob_dict!" % \
                    match_object.group('job_step_id')
                # clear the old job_string, store the old new_job_step
                job_steps[new_job_step['name']] = new_job_step
            job_string = ''
d540 1
a540 1
    job_adapter_reo = re.compile(r"\((?P<interface>[\w\d]+),([\w\d]+),(?P<sharing>[\w\d]+),(?P<USorIP>[\w\d]+)\)")
@


1.35
log
@run-at-risk
@
text
@d447 1
a447 1
        LLSTATUS = '/usr/lpp/LoadL/full/bin/llstatus -l'
d451 4
a454 29
    resource_reo = re.compile( r"""(^\s*Name\s*=\ (?P<Name>\S+)$)
            ((.|\n)*)
            (^\s*Adapter\s*=\ (?P<Adapter>.*?)$)
            ((.|\n)*)"""
        ,re.MULTILINE | re.VERBOSE)
    delimit_reo = re.compile(r"^===============================================================================$")
    for line in  os.popen(LLSTATUS).readlines() :
        resource_string = resource_string + line
        line_mo = None
        line_mo = delimit_reo.match(line)
        if line_mo != None :
            if found_start == 1 :
                # parse the resource_string
                resource_mo = resource_reo.search(resource_string)
                if resource_mo == None :
                    print "resource_mo is None"
                    print "resource_string is (%s)" % resource_string
                else :
                    resource_name =  resource_mo.group('Name')
                    # in case bogus info was returned from qm_LL,
                    # bail out if resources_dict doesn't have
                    # resource_name in it
                    if not resources_dict.has_key(resource_name) :
                        resource_string = ''
                        continue
                    resources_dict[resource_name]['Adapter'] =  resource_mo.group('Adapter')
                # clear the old resource_string
                resource_string = ''
            found_start = 1
d616 2
@


1.34
log
@*** empty log message ***
@
text
@d88 1
a88 1
    new_job_step['run-at-risk_int'] = 0
@


1.33
log
@added multiple-requirement resource spec
(only uses the first one, for now)
@
text
@d39 7
@


1.32
log
@moved in update_job_priorities,
@
text
@d19 1
d33 1
d363 5
d546 15
@


1.31
log
@added run_at_risk
@
text
@a621 175
def get_QOS_priority(QOS) :
    if string.atoi(QOS) < len(Catalina.QOS_PRIORITY_dict.keys()) :
        return Catalina.QOS_PRIORITY_dict[QOS]
    else :
        return 0

def get_QOS_target_expansion_factor(QOS) :
    # This returns the target expansion factor for
    # the different QOSs.
    if string.atoi(QOS) < len(Catalina.QOS_TARGETXF_dict.keys()) :
        return Catalina.QOS_TARGETXF_dict[QOS]
    else :
        return None

def get_QOS_target_queue_wait_time(QOS) :
    # This function returns a target queue wait time
    # for a given QOS.
    if string.atoi(QOS) < len(Catalina.QOS_TARGETQT_dict.keys()) :
        return Catalina.QOS_TARGETQT_dict[QOS]
    else :
        return None

def update_job_priorities (jobs_db_handle) :
    # priority calculation:
    # resource_number * Resource_Weight
    # expansion factor * Expansion_Factor_Weight
    # system queue time * System_Queue_Time_Weight
    # submit time * Submit_Time_Weight
    # QOS_priority * QOS_Priority_Weight
    # QOS_target_expansion_factor * QOS_Target_Expansion_Factor_Weight
    # QOS_target_queue_wait_time * QOS_Target_Queue_Wait_Time_Weight
    # Adjust these weights to emphasize different elements of the
    # priority calculation
    #Resource_Weight = 1100.0
    #Expansion_Factor_Weight = 10.0
    #System_Queue_Time_Weight = 0.1
    #Submit_Time_Weight = 0.0
    #QOS_Priority_Weight = 6000.0
    #QOS_Target_Expansion_Factor_Weight = 1
    #QOS_Target_Queue_Wait_Time_Weight = 1
    Resource_Weight = Catalina.RESOURCE_WEIGHT
    if Catalina.__dict__.has_key('LOCAL_ADMIN_WEIGHT') :
        Local_Admin_Weight = Catalina.LOCAL_ADMIN_WEIGHT
    else :
        Local_Admin_Weight = 0.0
    if Catalina.__dict__.has_key('LOCAL_USER_WEIGHT') :
        Local_User_Weight = Catalina.LOCAL_USER_WEIGHT
    else :
        Local_User_Weight = 0.0
    Expansion_Factor_Weight = Catalina.EXPANSION_FACTOR_WEIGHT
    System_Queue_Time_Weight = Catalina.SYSTEM_QUEUE_TIME_WEIGHT
    Submit_Time_Weight = Catalina.SUBMIT_TIME_WEIGHT
    Wall_Time_Weight = Catalina.WALL_TIME_WEIGHT
    QOS_Priority_Weight = Catalina.QOS_PRIORITY_WEIGHT
    QOS_Target_Expansion_Factor_Weight = Catalina.QOS_TARGET_EXPANSION_FACTOR_WEIGHT
    QOS_Target_Queue_Wait_Time_Weight = Catalina.QOS_TARGET_QUEUE_WAIT_TIME_WEIGHT
    jobs_shelf = jobs_db_handle[0]
    for key in jobs_shelf.keys() :
        # Set up a dict to store priority calculation terms for later reports
        priority_element_dict = {
          'Resource_Weight'                    : Resource_Weight,
          'Local_Admin_Weight'                 : Local_Admin_Weight,
          'Local_User_Weight'                  : Local_User_Weight,
          'Expansion_Factor_Weight'            : Expansion_Factor_Weight,
          'System_Queue_Time_Weight'           : System_Queue_Time_Weight,
          'Submit_Time_Weight'                 : Submit_Time_Weight,
          'Wall_Time_Weight'                   : Wall_Time_Weight,
          'QOS_Priority_Weight'                : QOS_Priority_Weight,
          'QOS_Target_Expansion_Factor_Weight' : QOS_Target_Expansion_Factor_Weight,
          'QOS_Target_Queue_Wait_Time_Weight'  : QOS_Target_Queue_Wait_Time_Weight
        }

        temp_job = jobs_shelf[key]

        # Get number of resources from initiatormap
        resourcemap_list = string.split(jobs_shelf[key]['initiatormap'], '+')
        resource_number = float(len(resourcemap_list))

        # Get local priority from local_priority_string
        if temp_job.has_key('local_admin_priority_string') and \
          temp_job['local_admin_priority_string'] != None :
            try :
                local_admin_float = float(temp_job['local_admin_priority_string'])
            except :
                local_admin_float = 0.0
        else :
            local_admin_float = 0.0
        if temp_job.has_key('local_user_priority_string') and \
          temp_job['local_user_priority_string'] != None :
            try :
                local_user_float = float(temp_job['local_user_priority_string'])
                if local_user_float > 0.0 :
                    local_user_float = 0.0
            except :
                local_user_float = 0.0
        else :
            local_user_float = 0.0

        # Calculate expansion factor
        expansion_factor = \
          ( ( Catalina.Now_float -
              float(temp_job['speculative_system_queue_time']) + \
            float(temp_job['wall_clock_limit']) ) / \
          float(temp_job['wall_clock_limit']) )

        # Calculate queue wait time
        queue_wait_time = Catalina.Now_float - float(temp_job['speculative_system_queue_time'])

        # Calculate submit wait time
        submit_wait_time = Catalina.Now_float - float(temp_job['SubmitTime'])

        # Get wall clock time
        wall_clock_time = temp_job['wall_clock_limit']

        # Get QOS priority
        QOS_priority = float(get_QOS_priority(temp_job['QOS']))

        # Get QOS target expansion factor
        QOS_target_expansion_factor = get_QOS_target_expansion_factor(temp_job['QOS'])
        if QOS_target_expansion_factor == None :
            QOS_target_xf_value = 0
        else :
            if expansion_factor >= QOS_target_expansion_factor :
                QOS_target_xf_value = float(Catalina.QOS_MAX_PRIORITY_dict[temp_job['QOS']])
            else :
                QOS_target_xf_value = 1 / (QOS_target_expansion_factor - expansion_factor)
            if QOS_target_xf_value > float(Catalina.QOS_MAX_PRIORITY_dict[temp_job['QOS']]) :
                QOS_target_xf_value = float(Catalina.QOS_MAX_PRIORITY_dict[temp_job['QOS']])
        # Get QOS target queue time
        QOS_target_queue_wait_time = get_QOS_target_queue_wait_time(temp_job['QOS'])
        if QOS_target_queue_wait_time == None :
            QOS_target_qwt_value = 0
        else :
            if queue_wait_time >= QOS_target_queue_wait_time :
                QOS_target_qwt_value = float(Catalina.QOS_MAX_PRIORITY_dict[temp_job['QOS']])
            else :
                QOS_target_qwt_value = 1 / (QOS_target_queue_wait_time - queue_wait_time)
            if QOS_target_qwt_value > float(Catalina.QOS_MAX_PRIORITY_dict[temp_job['QOS']]) :
                QOS_target_qwt_value = float(Catalina.QOS_MAX_PRIORITY_dict[temp_job['QOS']])

        priority_element_dict['resource_number'] = resource_number
        priority_element_dict['local_admin_float'] = local_admin_float
        priority_element_dict['local_user_float'] = local_user_float
        priority_element_dict['expansion_factor'] = expansion_factor
        priority_element_dict['queue_wait_time'] = queue_wait_time
        priority_element_dict['submit_wait_time'] = submit_wait_time
        priority_element_dict['wall_clock_time'] = wall_clock_time
        priority_element_dict['QOS_priority'] = QOS_priority
        priority_element_dict['QOS_target_xf_value'] = QOS_target_xf_value
        priority_element_dict['QOS_target_qwt_value'] = QOS_target_qwt_value

        if temp_job['system_priority_int'] != None :
            priority = float( Catalina.MAXPRIORITY + \
              temp_job['system_priority_int'] )
        else :
            priority = \
                resource_number * Resource_Weight + \
                local_admin_float * Local_Admin_Weight + \
                local_user_float * Local_User_Weight + \
                expansion_factor * Expansion_Factor_Weight + \
                queue_wait_time * System_Queue_Time_Weight + \
                submit_wait_time * Submit_Time_Weight + \
                wall_clock_time * Wall_Time_Weight + \
                QOS_priority * QOS_Priority_Weight + \
                QOS_target_xf_value * QOS_Target_Expansion_Factor_Weight + \
                QOS_target_qwt_value * QOS_Target_Queue_Wait_Time_Weight
            if Catalina.QOS_MAX_PRIORITY_dict.has_key(temp_job['QOS']) :
                max_pri = float(Catalina.QOS_MAX_PRIORITY_dict[temp_job['QOS']])
            else :
                max_pri = Catalina.MAXPRIORITY
            if priority > max_pri - max_pri * 0.1 :
                priority =  (priority * max_pri)/(priority + max_pri * 0.1)
	Catalina.update_object_attribute('priority', priority, temp_job, jobs_db_handle)
	Catalina.update_object_attribute('priority_element_dict', priority_element_dict, temp_job, jobs_db_handle)

@


1.30
log
@added job_start_warns_int to initialize_job
@
text
@d79 1
d351 7
@


1.29
log
@added check for Catalina.QOS_MAX_PRIORITY_dict.has_key(temp_job['QOS'])
@
text
@d78 1
@


1.28
log
@some SIM mode code
@
text
@d779 4
a782 1
            max_pri = float(Catalina.QOS_MAX_PRIORITY_dict[temp_job['QOS']])
@


1.27
log
@fixed Feature parsing problem
@
text
@d85 4
a88 1
    cmd = Catalina.HOMEDIR + '/___QJ_PLACEHOLDER___'
d238 4
a241 1
    LLQ = '/usr/lpp/LoadL/full/bin/llq -l | /usr/bin/grep -e "Job Step Id" -e Specify -e "Adapter Requirement"'
d361 4
a364 1
    QUERYMACHINES = Catalina.HOMEDIR + '/___QM_PLACEHOLDER___'
d421 4
a424 1
    LLSTATUS = '/usr/lpp/LoadL/full/bin/llstatus -l'
@


1.26
log
@changed 'continue's in try: statement to 'raise 'Continue''
@
text
@d491 3
a493 2
    Feature_reo = re.compile(r'Feature\s*==\s*"(.*?)"')
    feature_expression = r"re.search(' \1 ',resource['Feature'])"
d556 2
d561 2
d565 2
d568 3
@


1.25
log
@put in try: except: around line processing in get_resources_list
@
text
@d364 2
a365 2
                finished_found =1
                continue
d376 1
a376 1
                continue
@


1.24
log
@if string.atoi(dict['Pool']) fails, just use dict['Pool']
@
text
@a360 21
        finished_mo = finished_reo.match(line)
        if finished_mo != None :
            finished_found =1
            continue
        elements_list = string.split(line, '#cat_delim#')
        dict = {}
        for element in elements_list :
            if element != '' :
                name_value_list = string.split(element, ':')
                if len(name_value_list) == 1 :
                    name_value_list.append('')
                dict[name_value_list[0]] = string.strip(name_value_list[1])
        # Should check entire line, but for now, check for Machine
        if not dict.has_key('Machine') :
            continue
        resource_name = dict['Machine']
        new_resource = initialize_resource(resource_name)
        new_resource['Machine'] = dict['Machine']
        new_resource['Arch'] =  dict['Arch']
        new_resource['OpSys'] =  dict['OpSys']
        new_resource['Disk'] =  string.atoi(dict['Disk'])
d362 21
d384 25
d410 1
a410 26
            new_resource['Pool'] =  dict['Pool']
        class_instance_list = string.split(dict['ConfiguredClasses'], '+')
        new_resource['ConfiguredClasses_list'] = map(string.strip, class_instance_list)
        new_resource['AvailableClasses'] =  dict['AvailableClasses']
        class_instance_list = string.split(dict['AvailableClasses'], '+')
        available_classes_string = ''
        old_instance = class_instance_list[0]
        instance_counter = 1
        irange = range(len(class_instance_list))
        for i in irange :
            instance = class_instance_list[i]
            if instance != old_instance :
                available_classes_string = available_classes_string + ("%s(%s)" % (old_instance, instance_counter - 1))
                instance_counter = 1
                old_instance = instance
            elif i == irange[-1] :
                available_classes_string = available_classes_string + ("%s(%s)" % (old_instance, instance_counter))
            instance_counter = instance_counter + 1
        new_resource['AvailableClasses'] =  available_classes_string
        new_resource['Feature'] =  dict['Feature']
        new_resource['Max_Starters'] =  string.atoi(dict['Max_Starters'])
        new_resource['Memory'] =  string.atoi(dict['Memory'])
        new_resource['Cpus'] =  string.atoi(dict['Cpus'])
        new_resource['State'] =  Catalina.RM_TO_CAT_RESOURCE_dict[dict['State']]
        new_resource['State_Change_Time'] = Catalina.Now_float
        resources_dict[new_resource['Machine']] = new_resource
@


1.23
log
@removed CANCELCMD
@
text
@d382 4
a385 1
        new_resource['Pool'] =  string.atoi(dict['Pool'])
@


1.22
log
@removed SUBMITCMD
@
text
@a24 2
TESTJOB='testjob.LL'
CANCELCMD='/usr/lpp/LoadL/full/bin/llcancel'
d119 1
a119 1
    cmd_string = CANCELCMD + ' ' + job_step['name']
@


1.21
log
@added checks for completion of qj and qm
@
text
@a25 1
SUBMITCMD='/usr/lpp/LoadL/full/bin/llsubmit'
@


1.20
log
@changed \S+ to [\w\d] for adapter reo
put in check for resource['Adapter'] == None
@
text
@d84 2
d90 4
d117 2
d361 2
d364 4
d446 2
@


1.19
log
@use start_count_int in reservation
@
text
@d506 1
a506 1
    job_adapter_reo = re.compile(r"\((?P<interface>\S+),(\S+),(?P<sharing>\S+),(?P<USorIP>\S+)\)")
d564 1
a564 1
        if not re.search(ready_adapter_match_string, resource['Adapter']) :
@


1.18
log
@remember started job
@
text
@d762 2
a763 2
            if reservation.has_key('start_returncode_int') and \
              reservation['start_returncode_int'] == 0 :
d810 8
a817 7
                Catalina.update_object_attribute(
                  'start_returncode_int',
                  return_code_int,
                  reservation,
                  reservations_db_handle)
                print "setting start_returncode_int to (%s) for (%s)" % \
                  (return_code_int, reservation['job_runID'])
@


1.17
log
@use RM_TO_CAT_dict to translate node states
@
text
@d38 2
d748 1
d762 3
d782 1
a782 1
            jobs_to_run[job_stepid] = runstring
d785 2
d788 1
a788 1
        cmd = RUNJOB + ' ' + jobs_to_run[job]
d794 8
d803 18
@


1.16
log
@removed local_admin_priority_string and local_user_priority_string
from job update attributes
@
text
@d392 1
a392 1
        new_resource['State'] =  dict['State']
@


1.15
log
@added check for resource to have not resource.has_key('ConfiguredClasses_list')
@
text
@d35 1
a35 3
  'cat_requirements_string',
  'local_admin_priority_string',
  'local_user_priority_string'
@


1.14
log
@changed to ConfiguredClasses_list
@
text
@d553 1
a553 1
        if resource['ConfiguredClasses_list'] == None :
@


1.13
log
@added local_admin and local_user to update_sttributes
@
text
@d49 1
a49 1
    new_resource['ConfiguredClasses'] = None
d323 1
a323 1
                            if fields[0] == 'Catalina_res_bind' :
d373 1
a373 15
        configured_classes_string = ''
        old_instance = class_instance_list[0]
        instance_counter = 1
        irange = range(len(class_instance_list))
        for i in irange :
            instance = class_instance_list[i]
            if instance != old_instance :
                #configured_classes_list.append("%s(%s)" % (old_instance, instance_counter))
                configured_classes_string = configured_classes_string + ("%s(%s)" % (old_instance, instance_counter - 1))
                instance_counter = 1
                old_instance = instance
            elif i == irange[-1] :
                configured_classes_string = configured_classes_string + ("%s(%s)" % (old_instance, instance_counter ))
            instance_counter = instance_counter + 1
        new_resource['ConfiguredClasses'] =  configured_classes_string
d519 2
a520 2
    job_class_search_string = r"%s\((?P<class_amount>\d+)\)" % job_class_requirement
    job_class_reo = re.compile(job_class_search_string)
d553 1
a553 1
        if resource['ConfiguredClasses'] == None :
d555 3
a557 2
        job_class_mo = job_class_reo.search(resource['ConfiguredClasses'])
        if job_class_mo == None :
d560 1
a560 1
        elif string.atoi(job_class_mo.group('class_amount')) < job_initiator_per_node_int :
a697 1
                #QOS_target_xf_value = float(Catalina.MAXPRIORITY)
d701 2
a702 1

a708 1
                #QOS_target_qwt_value = float(Catalina.MAXPRIORITY)
d712 2
d741 3
a743 2
            if priority > float(Catalina.QOS_MAX_PRIORITY_dict[temp_job['QOS']]) :
                priority = float(Catalina.QOS_MAX_PRIORITY_dict[temp_job['QOS']])
@


1.12
log
@added string.strip to check for local_admin and local_user terms
@
text
@d30 9
a38 1
JOB_UPDATE_ATTRIBUTE_list = ['state', 'Dispatch_Time', 'allocated_hosts', 'completion_time', 'cat_requirements_string']
@


1.11
log
@*** empty log message ***
@
text
@d324 1
a324 1
                            elif fields[0] == 'Catalina_local_admin_priority' :
d327 1
a327 1
                            elif fields[0] == 'Catalina_local_user_priority' :
@


1.10
log
@changed ready_adapter_match_string to allow switch
@
text
@a27 22
NODERESTCODE="""
normal_re = re.compile(".*normal.*")
resource = input_tuple[0]
if resource['State'] == 'Down' :
    result = 'Down'
elif resource['State'] == 'Drain' :
    resutl = 'Drain'
elif resource['State'] == 'Drained' :
    result = 'Drained'
elif resource['State'] == 'None' :
    result = 'None'
elif resource['State'] == None :
    result = None
elif resource['State'] == 'Unknown' :
    result = 'Unknown'
elif resource['Max_Starters'] == 0 :
    result = 'Max_Starters=0'
elif normal_re.search(resource['ConfiguredClasses']) == None :
    result = 'NoNormalClass'
else :
    result = 0
"""
@


1.9
log
@added local_admin, local_user, wall_time priority elements
@
text
@d540 1
a540 1
          r'\(\S+,(READY|)\)'
@


1.8
log
@added checks for bad info from qm_LL in get_resources_list
@
text
@d346 6
d643 8
d654 1
d663 2
d668 1
a673 13
        priority_element_dict['Resource_Weight'] = Resource_Weight
        priority_element_dict['Expansion_Factor_Weight'] = \
          Expansion_Factor_Weight
        priority_element_dict['System_Queue_Time_Weight'] = \
          System_Queue_Time_Weight
        priority_element_dict['Submit_Time_Weight'] = \
          Submit_Time_Weight
        priority_element_dict['QOS_Priority_Weight'] = QOS_Priority_Weight
        priority_element_dict['QOS_Target_Expansion_Factor_Weight'] = \
          QOS_Target_Expansion_Factor_Weight
        priority_element_dict['QOS_Target_Queue_Wait_Time_Weight'] = \
          QOS_Target_Queue_Wait_Time_Weight

d680 20
d713 3
d742 2
d747 1
d758 2
d763 1
@


1.7
log
@cleaned up some...
@
text
@d370 3
d443 6
d450 1
a450 1
                # clear the old job_string, store the old new_job_step
@


1.6
log
@removed get_accepted_nodes_list
@
text
@a86 1
    #new_job_step['cat_requirements_string'] = None
a99 6
    #initiatormap_reo = re.compile(r"^initiatormap:(?P<initiatormap>.*)$")
    #comment_reo = re.compile(r"^comment:(?P<comment>.*)$")
    #state_reo = re.compile(r"^state:(?P<state>.*)$")
    #dispatchtime_reo = re.compile(r"^dispatchtime:(?P<dispatchtime>\d*)$")
    #submittime_reo = re.compile(r"^submittime:(?P<submittime>\d*)$")
    #completiontime_reo = re.compile(r"^completiontime:(?P<completiontime>\d*)$")
a117 24
            #stepid_mo = stepid_reo.match(element)
            #if stepid_mo != None :
            #    step_dict['fromhost'] = stepid_mo.group('fromhost')
            #    step_dict['cluster'] = stepid_mo.group('cluster')
            #    step_dict['proc'] = stepid_mo.group('proc')
            #    stepid = stepid_mo.group('stepid')
            #state_mo = state_reo.match(element)
            #if state_mo != None :
            #    step_dict['state'] = state_mo.group('state')
            #completiontime_mo = completiontime_reo.match(element)
            #if completiontime_mo != None :
            #    step_dict['completiontime'] = completiontime_mo.group('completiontime')
            #submittime_mo = submittime_reo.match(element)
            #if submittime_mo != None :
            #    step_dict['submittime'] = submittime_mo.group('submittime')
            #dispatchtime_mo = dispatchtime_reo.match(element)
            #if dispatchtime_mo != None :
            #    step_dict['dispatchtime'] = dispatchtime_mo.group('dispatchtime')
            #comment_mo = comment_reo.match(element)
            #if comment_mo != None :
            #    step_dict['comment'] = comment_mo.group('comment')
            ##initiatormap_mo = initiatormap_reo.match(element)
            #if initiatormap_mo != None :
            #    step_dict['initiatormap'] = initiatormap_mo.group('initiatormap')
a123 2
            #print "adding (%s) to runjob_dict" % stepid
            #print "(%s) machinemap is (%s)" % (step_dict['stepid'], step_dict[name_value_list[0]])
d182 2
a183 1
                if resources_dict[host]['State'] == 'Down' and \
a252 22
    #matchstr = re.compile( r"""(^\s*Job\ Step\ Id:\ (?P<job_step_id>\S+))
    #        (.*)
    #        (^\s*Owner:\ (?P<owner>\S+))
    #        (.*)
    #        (^\s*Status:\ (?P<status>\S+))
    #        (.*)
    #        (^\s*Class:\ (?P<job_class>\S+))
    #        (.*)
    #        (^\s*Wall\ Clk\ Hard\ Limit:\ (?P<wall_clock_limit>\S+))
    #        (.*)
    #        (^\s*Comment:\ (?P<comment>.*?)$)
    #        (.*)
    #        (^\s*Account:\ (?P<account>.*?)$)
    #        (.*)
    #        (^\s*Unix\ Group:\ (?P<group>\S+))
    #        (.*)
    #        (^\s*Adapter\ Requirement:\ (?P<adapter>\S*))
    #        (.*)
    #        (^\s*Requirements\ \ \ \ :\ (?P<requirements>.*?)$)
    #        (.*)"""
    #    ,re.MULTILINE | re.DOTALL | re.VERBOSE)
    #allocated_hosts_reo = re.compile( r"(?P<host>\S+)::" )
a258 5
            #sections = string.split(job_string, 'Allocated Host')
            #allocated_sections_list = sections[1:]
            #allocated_section_number = len(allocated_sections_list)
            #first_string = sections[0]
            #match_object = matchstr.search(first_string)
a268 1
                #new_job_step_name = match_object.group('job_step_id')
a269 9
                #new_job_step = initialize_job_step(new_job_step_name)
                #new_job_step['QOS'] = '0'
                #new_job_step['user'] = match_object.group('owner')
                #new_job_step['state'] = match_object.group('status')
                #new_job_step['job_class'] = match_object.group('job_class')
                #new_job_step['wall_clock_limit'] = string.atof(match_object.group('wall_clock_limit'))
                #new_job_step['account'] = match_object.group('account')
                #new_job_step['group'] = match_object.group('group')
                #new_job_step['adapter'] = match_object.group('adapter')
a270 17
                #new_job_step['requirements'] = match_object.group('requirements')
                #new_job_step['cat_requirements_string'] = get_requirements_string(match_object.group('requirements'))
                #matched_groups = match_object.groupdict()
                #if new_job_step['state'] == 'Running' or new_job_step['state'] == 'Starting' :
                #    complete_hosts_list = []
                #    for section in allocated_sections_list :
                #        raw_allocated_hosts_string = section
                #        hosts_list = allocated_hosts_reo.findall(
                #          raw_allocated_hosts_string)
                #        if len(hosts_list) == 0 :
                #            print "No allocated_hosts found!"
                #            print raw_allocated_hosts_string
                #            # Don't bail out, for now
                #            #raise 'NoAllocatedHosts', raw_allocated_hosts_string
                #        else :
                #            complete_hosts_list = complete_hosts_list + hosts_list
                #    new_job_step['allocated_hosts'] = complete_hosts_list
d272 15
d288 6
d296 4
a299 1
                    new_job_step['state'] = Catalina.RM_TO_CAT_JOB_dict[runjob_dict[job_step_id]['state']]
a311 1
                    new_job_step['Dispatch_Time'] = string.atof(runjob_dict[job_step_id]['dispatchtime'])
d313 2
d318 28
a345 16
                        allocated_hosts = string.split(runjob_dict[job_step_id]['machinemap'], '+')
                        new_job_step['allocated_hosts'] = allocated_hosts
                    new_job_step['comment'] = runjob_dict[job_step_id]['comment']
                    elements = string.split(runjob_dict[job_step_id]['comment'], ';')
                    for element in elements :
                        string.strip(element)
                        fields = string.split(element, '=')
                        if fields[0] == 'Catalina_res_bind' :
                            res_ids_list = []
                            raw_res_ids = string.split(fields[1], ':')
                            for id in raw_res_ids :
                                res_ids_list.append(string.strip(id))
                            new_job_step['reservation_binding'] =  res_ids_list
                        elif string.strip(fields[0]) == 'QOS' :
                            QOS = string.strip(fields[1])
                            new_job_step['QOS'] =  QOS
a377 1
        #configured_classes_list = []
a391 1
        #configured_classes_string = "".join(configured_classes_list)
a394 1
        #available_classes_list = []
a401 1
                #available_classes_list.append("%s(%s)" % (old_instance, instance_counter))
a407 1
        #available_classes_string = "".join(available_classes_list)
a557 4
                #print "requirements string: (%s)" % new_requirements_string
                #print "resource['Pool'] is (%s)" % resource['Pool']
                #print "resource['Arch'] is (%s)" % resource['Arch']
                #print "resource['OpSys'] is (%s)" % resource['OpSys']
@


1.5
log
@changed NODERESTCODE to check for node state and max starters
@
text
@a97 30
def get_accepted_nodes_list(node_restriction_code, resource_db_handle) :
    dict = resource_db_handle[0]
    resource_list = dict.values()
    accepted_nodes_list = []
    for resource in resource_list :
        if node_restriction_code != None :
            print "node_restriction_code (%s)" % node_restriction_code
            input_tuple = (resource,)
            acceptance = apply_policy_code(node_restriction_code, input_tuple)
        elif resource['State'] == 'Down' :
            acceptance = 'Down'
        elif resource['State'] == 'Drain' :
            acceptance = 'Drain'
        elif resource['State'] == 'Drained' :
            acceptance = 'Drained'
        elif resource['State'] == 'None' :
            acceptance = 'None'
        elif resource['State'] == None :
            acceptance = None
        elif resource['State'] == 'Unknown' :
            acceptance = 'Unknown'
        elif resource['Max_Starters'] == 0 :
            acceptance = 'Max_Starters=0'
        else :
            acceptance = 0
        if acceptance != 0 :
            continue
        accepted_nodes_list.append(resource['name'])
    return accepted_nodes_list

d361 1
a361 1
                    new_job_step['state'] = runjob_dict[job_step_id]['state']
@


1.4
log
@moved RUNJOB to run_jobs
@
text
@d28 22
a49 1
NODERESTCODE="if input_tuple[0]['ConfiguredClasses'] != None and re.search('normal', input_tuple[0]['ConfiguredClasses']) : result = 0"
@


1.3
log
@*** empty log message ***
@
text
@a30 1
RUNJOB='___RUNJOB_PLACEHOLDER___'
d797 1
@


1.2
log
@*** empty log message ***
@
text
@d31 1
a31 1
RUNJOB='rj_LL'
d117 1
a117 1
    cmd = Catalina.HOMEDIR + '/getinitmap'
d417 1
a417 1
    QUERYMACHINES = Catalina.QUERYMACHINES
@


1.1
log
@Initial revision
@
text
@d25 9
d78 30
d171 1
a171 2
    LoadL_cancel = '/usr/lpp/LoadL/full/bin/llcancel'
    cmd_string = LoadL_cancel + ' ' + job_step['name']
d799 1
a799 1
    RUNJOB = Catalina.HOMEDIR + '/runjob'
d846 1
a846 1
def get_configured_resources_list() :
@
