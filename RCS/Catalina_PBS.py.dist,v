head	1.55;
access;
symbols;
locks; strict;
comment	@# @;


1.55
date	2007.01.29.18.55.37;	author mmargo;	state Exp;
branches;
next	1.54;

1.54
date	2007.01.27.03.14.05;	author kenneth;	state Exp;
branches;
next	1.53;

1.53
date	2005.12.05.20.26.30;	author mmargo;	state Exp;
branches;
next	1.52;

1.52
date	2005.03.28.20.34.36;	author kenneth;	state Exp;
branches;
next	1.51;

1.51
date	2004.08.23.22.08.35;	author kenneth;	state Exp;
branches;
next	1.50;

1.50
date	2004.08.11.17.44.39;	author kenneth;	state Exp;
branches;
next	1.49;

1.49
date	2004.07.21.18.35.09;	author kenneth;	state Exp;
branches;
next	1.48;

1.48
date	2004.07.19.17.43.02;	author kenneth;	state Exp;
branches;
next	1.47;

1.47
date	2004.05.03.18.19.45;	author kenneth;	state Exp;
branches;
next	1.46;

1.46
date	2004.03.01.18.03.49;	author kenneth;	state Exp;
branches;
next	1.45;

1.45
date	2004.02.24.04.32.44;	author kenneth;	state Exp;
branches;
next	1.44;

1.44
date	2004.02.05.17.54.51;	author kenneth;	state Exp;
branches;
next	1.43;

1.43
date	2003.08.07.22.10.43;	author kenneth;	state Exp;
branches;
next	1.42;

1.42
date	2003.08.06.19.48.06;	author kenneth;	state Exp;
branches;
next	1.41;

1.41
date	2003.06.26.18.07.22;	author kenneth;	state Exp;
branches;
next	1.40;

1.40
date	2003.06.11.18.51.38;	author kenneth;	state Exp;
branches;
next	1.39;

1.39
date	2003.05.23.21.39.27;	author kenneth;	state Exp;
branches;
next	1.38;

1.38
date	2003.05.23.15.56.40;	author kenneth;	state Exp;
branches;
next	1.37;

1.37
date	2003.01.25.00.03.14;	author kenneth;	state Exp;
branches;
next	1.36;

1.36
date	2003.01.24.23.54.28;	author kenneth;	state Exp;
branches;
next	1.35;

1.35
date	2003.01.24.22.58.22;	author kenneth;	state Exp;
branches;
next	1.34;

1.34
date	2003.01.24.22.21.31;	author kenneth;	state Exp;
branches;
next	1.33;

1.33
date	2003.01.10.23.32.17;	author kenneth;	state Exp;
branches;
next	1.32;

1.32
date	2002.11.06.19.14.56;	author kenneth;	state Exp;
branches;
next	1.31;

1.31
date	2002.07.26.19.43.38;	author kenneth;	state Exp;
branches;
next	1.30;

1.30
date	2002.07.15.20.10.24;	author kenneth;	state Exp;
branches;
next	1.29;

1.29
date	2002.07.15.19.22.50;	author kenneth;	state Exp;
branches;
next	1.28;

1.28
date	2002.06.20.23.15.51;	author kenneth;	state Exp;
branches;
next	1.27;

1.27
date	2002.06.18.23.26.05;	author kenneth;	state Exp;
branches;
next	1.26;

1.26
date	2002.06.18.18.43.29;	author kenneth;	state Exp;
branches;
next	1.25;

1.25
date	2002.03.11.19.07.44;	author kenneth;	state Exp;
branches;
next	1.24;

1.24
date	2002.02.27.23.30.06;	author kenneth;	state Exp;
branches;
next	1.23;

1.23
date	2002.02.27.21.08.56;	author kenneth;	state Exp;
branches;
next	1.22;

1.22
date	2002.02.27.01.36.30;	author kenneth;	state Exp;
branches;
next	1.21;

1.21
date	2002.02.22.19.18.06;	author kenneth;	state Exp;
branches;
next	1.20;

1.20
date	2002.01.18.18.16.16;	author kenneth;	state Exp;
branches;
next	1.19;

1.19
date	2002.01.17.20.51.43;	author kenneth;	state Exp;
branches;
next	1.18;

1.18
date	2002.01.16.18.59.40;	author kenneth;	state Exp;
branches;
next	1.17;

1.17
date	2002.01.11.20.12.53;	author kenneth;	state Exp;
branches;
next	1.16;

1.16
date	2002.01.03.17.08.43;	author kenneth;	state Exp;
branches;
next	1.15;

1.15
date	2002.01.03.00.45.06;	author kenneth;	state Exp;
branches;
next	1.14;

1.14
date	2002.01.03.00.42.07;	author kenneth;	state Exp;
branches;
next	1.13;

1.13
date	2001.12.14.22.59.31;	author kenneth;	state Exp;
branches;
next	1.12;

1.12
date	2001.12.01.01.32.20;	author kenneth;	state Exp;
branches;
next	1.11;

1.11
date	2001.11.29.22.56.25;	author kenneth;	state Exp;
branches;
next	1.10;

1.10
date	2001.11.07.17.12.15;	author kenneth;	state Exp;
branches;
next	1.9;

1.9
date	2001.11.06.22.43.53;	author kenneth;	state Exp;
branches;
next	1.8;

1.8
date	2001.11.01.00.06.15;	author kenneth;	state Exp;
branches;
next	1.7;

1.7
date	2001.10.04.17.34.10;	author kenneth;	state Exp;
branches;
next	1.6;

1.6
date	2001.10.04.17.31.53;	author kenneth;	state Exp;
branches;
next	1.5;

1.5
date	2001.09.14.21.02.58;	author kenneth;	state Exp;
branches;
next	1.4;

1.4
date	2001.09.13.17.45.13;	author kenneth;	state Exp;
branches;
next	1.3;

1.3
date	2001.09.12.23.52.46;	author kenneth;	state Exp;
branches;
next	1.2;

1.2
date	2001.09.11.22.22.05;	author kenneth;	state Exp;
branches;
next	1.1;

1.1
date	2001.09.11.19.45.51;	author kenneth;	state Exp;
branches;
next	;


desc
@PBS module
@


1.55
log
@feature 582 added in get_job_steps_dict()
detects proc_hours
mmargo
@
text
@# PBS-specific Catalina names
# get node info with pbsqm
# get job info with pbsqj
# job info needed to match jobs to nodes:
# - user
# - group
# - account

import os
import re
import string
import time
import types
# Importing Catalina in order to use the insert_new_job function
# in update_job_priorities and Now_float
import Catalina

import sys

os.environ['PBS_DEFAULT'] = '___RMSERVER_DEFAULT_PLACEHOLDER___'

JOBSUFFIX=''
SUBMIT_OUTPUT_PATTERN=r'^(?P<job_id>\d+\.\S+)'
JOB_UPDATE_ATTRIBUTE_list = [
  'state',
  'Dispatch_Time',
  'task_hosts',
  'node_usage',
  'allocated_hosts',
  'resource_dict_list',
  'req_dict_list'
  ]

start_job_returncode_reo = re.compile("^rc from pbs_asyrunjob is >(?P<code>\d+)<$", re.MULTILINE)

def get_scheduler_time() :
    if Catalina.SERVERMODE == 'SIM' :
        Now_float = float(os.system(TIME_SIM))
    else :
        Now_float = time.time()
    return Now_float

def initialize_resource(resource_name) :
    new_resource = {}
    new_resource['name'] =  resource_name
    new_resource['Disk'] = None
    new_resource['Feature'] = None
    new_resource['properties_list'] = []
    new_resource['Machine'] = None
    new_resource['Arch'] = None
    new_resource['OpSys'] = None
    new_resource['Pool'] = None
    new_resource['ConfiguredClasses_list'] = [Catalina.DEFAULT_JOB_CLASS,]
    new_resource['AvailableClasses'] = None
    new_resource['Adapter'] = None
    new_resource['Feature'] = ''
    new_resource['Max_Starters'] = None
    new_resource['Memory'] = None
    new_resource['Cpus'] = None
    new_resource['State'] = None
    new_resource['speculative_state'] = None
    new_resource['State_Change_Time'] = Catalina.Now_float
    return new_resource

def initialize_job_step(job_step_name) :
    new_job_step = {}
    new_job_step['name'] = job_step_name
    new_job_step['QOS'] = '0'
    new_job_step['user'] = None
    new_job_step['state'] = None
    new_job_step['job_class'] = None
    new_job_step['wall_clock_limit'] = None
    new_job_step['comment'] = None
    new_job_step['account'] = None
    new_job_step['group'] = None
    new_job_step['adapter'] = None
    new_job_step['requirements'] = None
    new_job_step['req_dict_list'] = None
    new_job_step['system_queue_time'] = None
    new_job_step['submittime'] = None
    new_job_step['dispatchtime'] = None
    new_job_step['completiontime'] = None
    new_job_step['system_priority_int'] = None
    new_job_step['system_priority_mark_string'] = None
    new_job_step['ineligible_reason'] = None
    new_job_step['reservation_binding'] = []
    new_job_step['job_start_warns_int'] = 0
    new_job_step['resource_amount_int'] = 0
    return new_job_step

def get_runjob_dict() :
    finished_reo = re.compile("^qj FINISHED$")
    finished_found = 0
    runjob_dict = {}
    cmd = Catalina.HOMEDIR + '/___QJ_PLACEHOLDER___'
    for rawline in os.popen(cmd).readlines() :
        finished_mo = finished_reo.match(rawline)
        if finished_mo != None :
            finished_found = 1
            continue
        step_dict = {'Resource_List' : {}}
        line = string.strip(rawline)
        elements = string.split(line,'#cat_delim#')
        for element in elements :
            name_value_list = string.split(element, '#cat_sep#')
            if len(name_value_list) == 1 :
                name_value_list.append('')
            if name_value_list[0] == 'Resource_List' :
                if step_dict.has_key('Resource_List') :
                    step_dict['Resource_List'][name_value_list[1]] = \
                      name_value_list[2]
                else :
                    step_dict['Resource_List'] = \
                      { name_value_list[1] : name_value_list[2] }
            elif name_value_list[0] == 'resources_used' :
                if step_dict.has_key('resources_used') :
                    step_dict['resources_used'][name_value_list[1]] = \
                      name_value_list[2]
                else :
                    step_dict['resources_used'] = \
                      { name_value_list[1] : name_value_list[2] }
            else :
                step_dict[name_value_list[0]] = name_value_list[1:]
            if name_value_list[0] == 'job_name' :
                stepid = name_value_list[1]
        if not step_dict.has_key('job_name') :
            continue
        runjob_dict[stepid] = step_dict
    if finished_found != 1 :
        raise 'IncompleteQJ'
    return runjob_dict

def preempt_job(job_step, events_db_handle) :
    # job preemption not implemented for PBS, yet.
    raise 'PreemptJobFailure', job_step
    #cmd_string = Catalina.PREEMPTCMD + ' ' + job_step['name']
    #output = 'llpreempt: Preempt command has been sent to the central manager.'
    #if Catalina.SERVERMODE == 'NORMAL' :
    #    return_string = os.popen(cmd_string).read()
    #    mo = re.match(output, return_string)
    #    if mo == None :
    #        raise 'PreemptJobFailure', job_step
    #else :
    #    print cmd_string
    #    return_string = ''
    #event = {
    #  'name' : 'preempt_job',
    #  'cmd' : cmd_string,
    #  'return_string' : return_string
    #  }
    #Catalina.log_event(event, events_db_handle)

## Martin W. Margo
## 11/30/2005 10:30 AM
## I modify cancel_job() to allow for reason why it was cancelled and pass
## it on to the user through email via pbs. 
## Torque supports qdel -m <message> command which allows the message to be
## propagated to the user. 
## To ensure backward compatibility, I will use default parameter message
def cancel_job(job_step, events_db_handle, message=None) :
    if (message != None):
        #use the message and use it to cancel jobs
        #qdel -m 'Overrun job detected. I will kill it' 29101
        cmd_string = Catalina.CANCELCMD + ' -m \'' + message + '\' ' \
            + job_step['name']
    else:
        cmd_string = Catalina.CANCELCMD + ' ' + job_step['name']
    
    output = ''
    if Catalina.SERVERMODE == 'NORMAL' :
        return_string = os.popen(cmd_string).read()
        mo = re.match(output, return_string)
        if mo == None :
            raise 'CancelJobFailure', job_step
    else :
        print cmd_string
        return_string = ''
    event = {
      'name' : 'cancel_job',
      'cmd' : cmd_string,
      'return_string' : return_string
      }
    Catalina.log_event(event, events_db_handle)

def cancel_bad_jobs(jobs_db_handle, resources_db_handle, events_db_handle) :
    jobs_dict = jobs_db_handle[0]
    jobs_list = jobs_dict.values()
    resources_dict = resources_db_handle[0]
    resources_list = resources_dict.values()
    for job in jobs_list :
        if job['state'] == 'Starting' :
            if Catalina.Now_float - job['Dispatch_Time'] > \
              Catalina.JOB_START_TIME_LIMIT :
                event = {
                  'name' : 'bad_job',
                  'type' : 'JOB_START_TIME_LIMIT violation',
                  'job' : job['name'],
                  'now' : Catalina.Now_float,
                  'Dispatch_Time' : job['Dispatch_Time']
                  }
                Catalina.log_event(event, events_db_handle)
                print "canceling %s in state %s" % (job['name'], job['state'])
                try :
                    cancel_job(job, events_db_handle)
                except :
                    continue
                message = """
%s
job (%s) (user %s), in state Starting for %s seconds,
has exceeded JOB_START_TIME_LIMIT (%s).  This job will
be canceled.  Please investigate the cause of job start
failure.""" % \
(time.asctime(time.localtime(Catalina.Now_float)), job['name'],
  job['user'], Catalina.Now_float - job['Dispatch_Time'], Catalina.JOB_START_TIME_LIMIT)
                subject = "Job exceeded JOB_START_TIME_LIMIT, %s, %s" % \
                  (job['name'], job['user'])
                recipient = Catalina.MAIL_RECIPIENT + ' ' + job['user']
                Catalina.warn(message, subject, recipient)
        if job['state'] in ['Starting', 'Running'] :
            down_hosts_list = []
            for host in job['allocated_hosts'] :
                if resources_dict.has_key(host) and \
                  resources_dict[host]['State'] == 'Down' and \
                  Catalina.Now_float - resources_dict[host]['State_Change_Time'] \
                  > Catalina.RESOURCE_DOWN_TIME_LIMIT :
                    event = {
                      'name' : 'bad_job',
                      'type' : 'RESOURCE_DOWN_TIME_LIMIT violation',
                      'job' : job['name'],
                      'host' : host,
                      'State' : resources_dict[host]['State'],
                      'now' : Catalina.Now_float,
                      'State_Change_Time' : job['Dispatch_Time']
                      }
                    Catalina.log_event(event, events_db_handle)
                    down_hosts_list.append(host)
            if len(down_hosts_list) > 0 :
                event = {
                  'name' : 'bad_job',
                  'type' : 'RESOURCE_DOWN_TIME_LIMIT violation',
                  'job' : job['name'],
                  'now' : Catalina.Now_float,
                  'State_Change_Time' : job['Dispatch_Time']
                  }
                Catalina.log_event(event, events_db_handle)
                print "Down node allocated for job %s in state %s with down nodes %s" % \
                  (job['name'], job['state'], down_hosts_list)
                message = """
%s
job (%s) (user %s), in state %s has down nodes:
Please check to see if this job actually has Down nodes.
If so, the job may be stuck waiting for a response from the down nodes.
It may be necessary to manually clear the job.
""" % \
(time.asctime(time.localtime(Catalina.Now_float)), job['name'],
  job['user'], job['state'], )
                #for host in down_hosts_list :
                    #purge_line = "\n/usr/lpp/LoadL/full/bin/llctl -h %s purge %s" % \
                    #  (jobs_dict[job['name']]['fromhost'], host)
                    #message = message + purge_line
                #subject = "Job has Down Nodes %s, %s" % \
                #  (job['name'], job['user'])
                #recipient = Catalina.MAIL_RECIPIENT
                Catalina.catsyslog(message, 'crit')
                
def get_job_step_state(job_step) :
    LoadL_state = job_step['state']
    if LoadL_state == 'Starting' :
        return 'STARTING'
    if LoadL_state == 'Running' :
        return 'RUNNING'
    elif LoadL_state == 'Idle' :
        return 'IDLE'
    elif LoadL_state == 'Completed' :
        return 'COMPLETED'
    elif LoadL_state == 'Removed' :
        return 'REMOVED'
    else :
        return 'OTHER'

def get_job_steps_dict() :
    Now_tuple = time.localtime(Catalina.Now_float)
    Now_year = Now_tuple[0]
    runjob_dict = get_runjob_dict()
    pbs_job_start_reo = re.compile(r"Job started on (?P<date>\w+\s+\w+\s+\w+) at (?P<time>\d\d:\d\d)")
    catalina_job_start_reo = re.compile(r"Catalina job start time \((?P<date>\d+)\)")
    job_steps = {}
    new_job_step_id = None
    for job_step_id in runjob_dict.keys() :
        new_job_step = initialize_job_step(job_step_id)
        if Catalina.USERNAMESUFFIX == '@@IGNORE' :
            new_job_step['user'] = string.split(runjob_dict[job_step_id]['Job_Owner'][1],'@@')[0]
        else :
            new_job_step['user'] = runjob_dict[job_step_id]['Job_Owner'][1]
        if Catalina.RM_TO_CAT_JOB_dict.has_key(runjob_dict[job_step_id]['job_state'][1]) :
            new_job_step['state'] = Catalina.RM_TO_CAT_JOB_dict[runjob_dict[job_step_id]['job_state'][1]]
        else :
            new_job_step['state'] = 'Unknown'
        new_job_step['job_class'] = runjob_dict[job_step_id]['queue'][1]
        if runjob_dict[job_step_id]['Resource_List'].has_key('walltime') :
            #print "job has walltime"
            raw_walltime_string = runjob_dict[job_step_id]['Resource_List']['walltime']
            #print "raw_walltime_string (%s)" % raw_walltime_string
            (hour, min, sec) = string.split(raw_walltime_string, ':')
            wall_clock_limit = \
              string.atof(hour) * 3600 + \
              string.atof(min)  * 60 + \
              string.atof(sec)
            new_job_step['wall_clock_limit'] = wall_clock_limit
        else :
            print "job has no walltime"
            new_job_step['wall_clock_limit'] = 7200.0
        if runjob_dict[job_step_id].has_key('Account_Name') :
            new_job_step['account'] = runjob_dict[job_step_id]['Account_Name'][1]
        else :
            new_job_step['account'] = None
        if runjob_dict[job_step_id].has_key('group') :
            new_job_step['group'] = runjob_dict[job_step_id]['egroup'][1]
        # example of how to pull a specific requirement out of the
        # Resource_List.  this needs to match the nodes?
        #if runjob_dict[job_step_id]['Resource_List'].has_key('mem') :
        #    mem_string = runjob_dict[job_step_id]['Resource_List']['mem']
        #else :
        #    mem_string = '0'
        requirements_string = "resource['ntype_string'] == 'cluster'"
        # take only the first set of node properties
        # 2:hippi:ppn=2:fat
        # tg-c002:ppn=1:compute+tg-c003
        # tg-c002:ppn=1:compute+tg-c003+2:compute
        if not runjob_dict[job_step_id]['Resource_List'].has_key('nodes') :
            print "Job (%s) does not have 'nodes' in Resource_List!" % job_step_id
            #continue
            node_spec_string = '1:ppn=1'
        else :
            node_spec_string = runjob_dict[job_step_id]['Resource_List']['nodes']
        node_spec_global_tuple = string.split(node_spec_string, '#')
        node_spec_list = string.split(node_spec_global_tuple[0], '+')
        node_usage = 'node_exclusive'
        if len(node_spec_global_tuple) > 1 :
            for global_attribute in node_spec_global_tuple[1:] :
                if global_attribute == 'shared' :
                    node_usage = 'node_shared'
                for node_spec in node_spec_list :
                    node_spec = node_spec + ':' + global_attribute
        new_job_step['node_usage'] = node_usage
        #spec_list = string.split(node_spec_string, '+')
        spec_list = node_spec_list
        node_count = 0
        ppn_reo = re.compile(r"^ppn=(?P<tasks>\d+)$")
        #parens_start = 0
        # if the first group is a number, increment total node count.
        # else if it's a resource name, put that in requirements string
        # and increment node count by 1.
        # This only handles ppn and features in the node properties list
        # For now, assume that each resource is a node
        #initiator_list = []
        #for req_dict in req_dict_list :
        #    initiator_list.append(`req_dict['amount_int']`)
        #initiatormap = string.join(initiator_list,'+')
        initiator_list = []
        req_dict_list = []
        for spec_index in range(len(spec_list)) :
            spec = spec_list[spec_index]
            spec_elements = string.split(spec, ':')
            this_req_dict = {'found_ppn' : 0}
            this_req_list = []
            found_ppn = 0
            for index in range(len(spec_elements)) :
                if index == 0 :
                    spec_mo = re.match(r"\d+",spec_elements[index])
                    if spec_mo != None :
                        node_count = node_count + int(spec_elements[index])
                        this_req_dict['amount_int'] = int(spec_elements[index])
                    else :
                        node_count = node_count + 1
                        this_req_dict['amount_int'] = 1
                        this_req_list.append("resource['name'] == '%s' " % spec_elements[0])
                else :
                    ppn_mo = ppn_reo.match(spec_elements[index])
                    if ppn_mo != None :
                        this_req_dict['found_ppn'] = 1
                        this_req_list.append("resource.has_key('Cpus') and (resource['Cpus'] >= %s) " % (ppn_mo.group('tasks'), ))
                        this_req_dict['ppn_int'] = int(ppn_mo.group('tasks'))
                    else :
                        this_req_list.append("'" + spec_elements[index] + "'" + " in resource['properties_list'] ")
            if this_req_dict['found_ppn'] == 0 :
                this_req_dict['ppn_int'] = 1
            this_req_string = ''
            for req_index in range(len(this_req_list)) :
                this_req_string = this_req_string + this_req_list[req_index]
                if req_index < len(this_req_list) - 1 :
                    this_req_string = this_req_string + ' and '
            this_req_dict['this_req_string'] = this_req_string
            req_dict_list.append(this_req_dict)
        procs_list = []
        for dict in req_dict_list :
            for index in range(dict['amount_int']) :
                procs_list.append(`dict['ppn_int']`)
        initiatormap = string.join(procs_list,'+')
        new_job_step['req_dict_list'] = req_dict_list
        new_job_step['initiatormap'] = initiatormap
        new_job_step['requirements'] = requirements_string
        new_job_step['cat_requirements_string'] = get_requirements_string(new_job_step['requirements'])
        new_job_step['SubmitTime'] = string.atof(runjob_dict[job_step_id]['qtime'][1])
        if new_job_step['state'] == 'Running' :
            if runjob_dict[job_step_id].has_key('comment') :
                job_comment = runjob_dict[job_step_id]['comment'][1]
            else :
                job_comment = ""
            #job_start_mo = job_start_reo.match(job_comment)
            #if job_start_mo != None :
            #    date = job_start_mo.group('date')
            #    time = job_start_mo.group('time')
            #    job_start_string = date + ' ' + time
            # Need to take a guess at the year.  Take the year
            # from Now_float.  Use that in job_start_tuple.  If
            # the resulting time is greater than Now_float, subtract
            # one from the year.  Assume that it won't be more than one off.
            pbs_job_start_mo = pbs_job_start_reo.match(job_comment)
            catalina_job_start_mo = catalina_job_start_reo.match(job_comment)
            if pbs_job_start_mo != None :
                job_start_tuple = time.strptime(
                  job_comment,
                  "Job started on %a %b %d at %H:%M"
                  )
                job_start_tuple = (Now_year,) + job_start_tuple[1:-1] + (-1,)
                #print "job_start_tuple (%s)" % (job_start_tuple,)
                job_start_float = time.mktime(job_start_tuple)
                # if the guessed year makes the job start time more than
                # 30 days in the future, assume it should be the previous year
                if job_start_float > Catalina.Now_float + 30*24*60*60 :
                    print "job_start_float (%s) > Catalina.Now_float (%s)" % (time.asctime(time.localtime(job_start_float)), time.asctime(time.localtime(Catalina.Now_float)))
                    job_start_tuple = (Now_year - 1,) + job_start_tuple[1:]
                job_start_float = time.mktime(job_start_tuple)
                new_job_step['Dispatch_Time'] = job_start_float
            elif catalina_job_start_mo != None :
                print "Found Catalina start time"
                new_job_step['Dispatch_Time'] = string.atof(catalina_job_start_mo.group('date'))
            elif runjob_dict[job_step_id].has_key('resources_used') and \
              runjob_dict[job_step_id]['resources_used'].has_key('walltime') :
                hms_string = runjob_dict[job_step_id]['resources_used']['walltime']
                hours, min, sec = string.split(hms_string, ':')
                walltime_sec = string.atof(hours) * 3600 + \
                               string.atof(min) * 60 + \
                               string.atof(sec)
                new_job_step['Dispatch_Time'] = Catalina.Now_float - walltime_sec
            else :
                new_job_step['Dispatch_Time'] = string.atof(runjob_dict[job_step_id]['mtime'][1])
            #new_job_step['Dispatch_Time'] = string.atof(runjob_dict[job_step_id]['mtime'][1])
            raw_allocated_hosts = string.split(runjob_dict[job_step_id]['exec_host'][1], '+')
            new_job_step['allocated_hosts'] = []
            for host in raw_allocated_hosts :
                trimmed_host = host[:-2]
                new_job_step['allocated_hosts'].append(trimmed_host)
            new_job_step['task_hosts'] = new_job_step['allocated_hosts']
        elements = string.split(runjob_dict[job_step_id]['Variable_List'][1], ',')
        for element in elements :
            string.strip(element)
            fields = string.split(element, '=')
            if string.strip(fields[0]) == 'Catalina_res_bind' :
                res_ids_list = []
                raw_res_ids = string.split(fields[1], ':')
                for id in raw_res_ids :
                    res_ids_list.append(string.strip(id))
                new_job_step['reservation_binding'] =  res_ids_list
            elif string.strip(fields[0]) == 'QOS' :
                QOS = string.strip(fields[1])
                try :
                    testint = string.atoi(QOS)
                except :
                    new_job_step['QOS'] =  '0'
                else :
                    new_job_step['QOS'] =  QOS
            elif string.strip(fields[0]) == 'Catalina_local_admin_priority' :
                local_admin_priority_string = string.strip(fields[1])
                new_job_step['local_admin_priority_string'] = local_admin_priority_string
            elif string.strip(fields[0]) == 'Catalina_local_user_priority' :
                local_user_priority_string = string.strip(fields[1])
                new_job_step['local_user_priority_string'] = local_user_priority_string
            elif string.strip(fields[0]) == 'Catalina_run_at_risk' :
                run_at_risk_string = string.strip(fields[1])
                if run_at_risk_string in ['Yes','YES','yes','Y','y','1'] :
                    new_job_step['run_at_risk_int'] = 1
            elif string.strip(fields[0]) == 'proc_hours' :
                proc_hours = string.strip(fields[1])
                new_job_step['proc_hours'] = proc_hours
        if runjob_dict[job_step_id]['Resource_List'].has_key('nodect') :
            node_count = string.atoi(runjob_dict[job_step_id]['Resource_List']['nodect'])
        else :
            node_count = 1
        if runjob_dict[job_step_id]['Resource_List'].has_key('nodes') :
            new_job_step['node_spec_string'] = runjob_dict[job_step_id]['Resource_List']['nodes']
        else :
            new_job_step['node_spec_string'] = '1:ppn=1'
        #new_job_step['initiatormap'] = (ppn_string + '+') * node_count
        #new_job_step['initiatormap'] = new_job_step['initiatormap'][:-1]
        new_job_step['resource_amount_int'] = node_count
        job_steps[new_job_step['name']] = new_job_step
    return job_steps
            
def get_resources_list() :
    QUERYMACHINES = Catalina.HOMEDIR + '/___QM_PLACEHOLDER___'
    machine_lines_list = os.popen(QUERYMACHINES).readlines()
    resources_dict = {}
    finished_reo = re.compile("^qm FINISHED$")
    finished_found = 0
    for line in machine_lines_list :
        finished_mo = finished_reo.match(line)
        if finished_mo != None :
            finished_found = 1
            continue
        elements_list = string.split(line, '#cat_delim#')
        dict = {}
        for element in elements_list :
            if element != '' :
                name_value_list = string.split(element, '#cat_sep#')
                if len(name_value_list) == 1 :
                    name_value_list.append('')
                dict[name_value_list[0]] = name_value_list[1:]
        if not dict.has_key('node_name') :
            continue
        resource_name = dict['node_name'][0]
        new_resource = initialize_resource(resource_name)
        new_resource['Machine'] = dict['node_name'][0]
        if dict.has_key('np') :
            new_resource['Cpus'] =  string.atoi(dict['np'][1])
        elif dict.has_key('pcpus') :
            new_resource['Cpus'] =  string.atoi(dict['pcpus'][1])
        # OpenPBS does not enforce memory or cpu on slave nodes.
        new_resource['ConsumableCpus'] = 0
        new_resource['ConsumableMemory'] = 0
        #new_resource['Cpus'] = 0
        new_resource['Memory'] = 0
        new_resource['ntype_string'] =  dict['ntype'][1]
        if dict.has_key('properties') :
            new_resource['properties_list'] = string.split(dict['properties'][1],',')
        try :
            new_resource['State'] = \
              Catalina.RM_TO_CAT_RESOURCE_dict[dict['state'][1]]
        except :
            new_resource['State'] = 'Down'
        #print "in get_resources_list, new_resource['State'] (%s)" % \
        #  new_resource['State']
        new_resource['State_Change_Time'] = Catalina.Now_float
        resources_dict[new_resource['Machine']] = new_resource
    
    resources = resources_dict.values()
    if finished_found != 1 :
        raise 'IncompleteQM'
    return resources

def get_requirements_string(old_requirements_string) :
    new_requirements_string = old_requirements_string
    return new_requirements_string
    
def get_resource_dict_list(job_step, resources_db_handle) :
    # returns list of dict of amounts and resource objects that match job_step
    if job_step.has_key('req_dict_list') and type(job_step['req_dict_list']) is types.ListType :
        req_dict_list = job_step['req_dict_list']
    else :
        if job_step.has_key('resource_amount_int') :
            amount_int = job_step['resource_amount_int']
        else :
            amount_int = None
        resource_list = [ {'amount_int' : amount_int, 'resource_dict' : resources_db_handle[0] }, ]
        return resource_list
    screened_resource_list = []
    resources_shelf = resources_db_handle[0]
    this_resource_dict_list = []
    for req_dict in req_dict_list :
        resource_dict = {}
        resource_dict['amount_int'] = req_dict['amount_int']
        new_requirements_string = req_dict['this_req_string']
        resource = None
        if new_requirements_string == '' :
            compiled_nrq = compile('1', '<string>', 'eval')
        else :
            compiled_nrq = compile(new_requirements_string, '<string>', 'eval')
        this_resource_dict = {}
        for key in resources_shelf.keys() :
            to_be_continued = 0
            resource = resources_shelf[key]
            try :
                if not eval(compiled_nrq) :
                    to_be_continued = 1
            except NameError :
                print "NameError Bad requirements string(%s) for job (%s)!" % (job_step['requirements'], job_step['name'])
                print "resource (%s)" % resource
                continue
            except KeyError :
                print "KeyError Bad requirements string(%s) for job (%s)!" % (job_step['requirements'], job_step['name'])
                continue
            if to_be_continued == 1 :
                continue
            this_resource_dict[resource['name']] = {}
        resource_dict['resource_dict'] = this_resource_dict
        this_resource_dict_list.append(resource_dict)
    return this_resource_dict_list

def get_resource_list(job_step, resources_db_handle) :
    if job_step.has_key('resource_dict_list') :
        resource_dict_list = job_step['resource_dict_list']
    else :
        resource_dict_list = get_resource_dict_list(job_step, resources_db_handle)
    node_list = []
    for resource_dict in resource_dict_list :
        node_list = node_list + resource_dict['resource_dict'].values()
    return node_list

def get_resource_name_list(resource_list) :
    names = []
    for resource in resource_list :
        names.append(resource['name'])
    return names

def run_jobs(events_db_handle, jobs_db_handle, resources_db_handle, reservations_db_handle) :
    #start_job_returncode_reo = start_job_returncode_reo
    ppn_reo = re.compile("ppn=\d+")
    RUNJOB='___RUNJOB_PLACEHOLDER___'
    print "in run_jobs"
    RUNJOB = Catalina.HOMEDIR + '/' + RUNJOB
    # all dbs can be read
    jobs_dict = jobs_db_handle[0]
    resources_dict = resources_db_handle[0]
    reservations_dict = reservations_db_handle[0]
    jobs_to_run = {}
    for reservation in reservations_dict.values() :
        if reservation['purpose_type_string'] != 'job' :
            continue
        start_time_float = reservation['start_time_float']
        if (Catalina.Now_float + 1) >= start_time_float and (Catalina.Now_float - start_time_float) <= Catalina.FUDGE_FACTOR/2 :
            if reservation.has_key('start_count_int') and \
              reservation['start_count_int'] >= 1 :
                continue
            job_stepid = reservation['job_runID']
            if jobs_dict[job_stepid]['state'] != 'Idle' :
                continue
            node_list = reservation['node_list']
            node_spec_string = jobs_dict[job_stepid]['node_spec_string']
            node_spec_global_tuple = string.split(node_spec_string, '#')
            node_spec_list = string.split(node_spec_global_tuple[0], '+')
            node_usage = 'node_exclusive'
            if len(node_spec_global_tuple) > 1 :
                for global_attribute in node_spec_global_tuple[1:] :
                    if global_attribute == 'shared' :
                        node_usage = 'node_shared'
                    for node_spec in node_spec_list :
                        node_spec = node_spec + ':' + global_attribute
            # assume no other properties, besides ppn are present
            node_ppn_list = []
            for node_spec in node_spec_list :
                split_tuple = string.split(node_spec, ':')
                n_string = split_tuple[0]
                if len(split_tuple) < 2 :
                    ppn_string = 'ppn=1'
                else :
                    ppn_string = split_tuple[1]
                    if ppn_reo.match(ppn_string) == None :
                        ppn_string = 'ppn=1'
                try :
                    n_int = string.atoi(n_string)
                except :
                    n_int = 1
                for index in range(1,n_int+1) :
                    # for non-rectangular initiatormap,
                    # use a separate ppn_string for each
                    # element of the node_ppn_list.
                    node_ppn_list.append( ppn_string )
            # further, assume that node_list was created to
            # match the order of the node_spec_string
            node_destination_string = ''
            node_range = range(len(node_list))
            for index in node_range :
                #node_destination_string = string.join(node_list, '+')
                node_destination_string = \
                  node_destination_string + \
                  node_list[index] + ':' + \
                  node_ppn_list[index]
                if index < node_range[-1] :
                    node_destination_string = node_destination_string + '+'
            print "node_destination_string (%s)" % node_destination_string
            #fromhost = jobs_dict[job_stepid]['fromhost']
            #cluster = jobs_dict[job_stepid]['cluster']
            #proc = jobs_dict[job_stepid]['proc']
            #initiatormap = jobs_dict[job_stepid]['initiatormap']
            #resourcemap_list = string.split(initiatormap,'+')
            #resourcemap_string = ''
            #resourcemap_list.reverse()
            #for i in range(len(resourcemap_list)) :
            #    for j in range(string.atoi(resourcemap_list[i])) :
            #        resourcemap_string = resourcemap_string + ' ' + \
            #            node_list[i]
            runstring = ' ' + job_stepid + ' ' + node_destination_string
            jobs_to_run[job_stepid] = (runstring, reservation)
            Catalina.update_object_attribute('Dispatch_Time', Catalina.Now_float, jobs_dict[job_stepid], jobs_db_handle)
            # alternatively:
            # jobs_dict[job_stepid]['Dispatch_Time'] = Catalina.Now_float
    print "len(jobs_to_run.keys()) is (%s)" % len(jobs_to_run.keys())
    for job in jobs_to_run.keys() :
        run_string = jobs_to_run[job][0]
        reservation = jobs_to_run[job][1]
        return_string = None
        cmd = RUNJOB + ' ' + run_string
        if Catalina.SERVERMODE == 'NORMAL' :
            print "really running job..."
            return_string = os.popen(cmd).readlines()
            print return_string
        else :
            return_string = \
              [
              'adding to nodelist (tf183i)\012',
              'adding to nodelist (tf183i)\012',
              'adding to nodelist (tf184i)\012',
              'adding to nodelist (tf184i)\012',
              'rc from pbs_asyrunjob is >0<\012'
              ]
            print "%s" % cmd
        if return_string != None :
            joined_return_string = string.join(return_string,'\n')
            start_job_returncode_mo = start_job_returncode_reo.search(joined_return_string)
        if start_job_returncode_mo != None :
            if start_job_returncode_mo.groupdict().has_key('code') :
                return_code_int = string.atoi(start_job_returncode_mo.group('code'))
                print "return_code_int is (%s)" % return_code_int
                if return_code_int == 0 :
                    Catalina.update_object_attribute(
                      'start_count_int',
                      1,
                      reservation,
                      reservations_db_handle)
                    print "setting start_count_int to (%s) for (%s)" % \
                      (1, reservation['job_runID'])
            else :
                print "no 'code' group found"
        else :
            print "start_job_returncode_mo == None"
        event = {
          'name' : 'run_jobs',
          'cmd' : cmd,
          'return_string' : return_string
          }
        Catalina.log_event(event, events_db_handle)
            

def get_configured_resources_list(resources_db_handle) :
#    def strip_newline(line) :
#        stripped_line = line[:-1]
#        return stripped_line
#    cmd_string = '___CAT_PLACEHOLDER___ ' + Catalina.LOADL_ADMIN_FILE + " | ___GREP_PLACEHOLDER___ 'type = machine' | ___GREP_PLACEHOLDER___ -v default | ___GREP_PLACEHOLDER___ -v ^# | ___AWK_PLACEHOLDER___ -F: '{print $1}'"
#    lines = os.popen(cmd_string).readlines()
#    stripped_lines = map(strip_newline, lines)
#    configured_resources_list = map( initialize_resource, stripped_lines)
#    return configured_resources_list
    configured_resources_list = map( initialize_resource, resources_db_handle[0].keys() )
    return configured_resources_list
@


1.54
log
@add speculative_state attribute to resource
@
text
@d484 3
@


1.53
log
@Modify cancel_job() to accept optional parameter messages
message is then passed to qdel command and sent to the user
this message is not null if invoked with canceloverrunjob
Martin W. Margo
@
text
@d61 1
@


1.52
log
@insert dummy preempt_job function
@
text
@d152 16
a167 2
def cancel_job(job_step, events_db_handle) :
    cmd_string = Catalina.CANCELCMD + ' ' + job_step['name']
@


1.51
log
@removed gmtime
@
text
@d132 20
@


1.50
log
@resource_amount_int to initialize_job
@
text
@d178 1
a178 1
(time.asctime(time.gmtime(Catalina.Now_float)), job['name'],
d220 1
a220 1
(time.asctime(time.gmtime(Catalina.Now_float)), job['name'],
@


1.49
log
@deal with tg-c131 failure to convert to int, assume 1
@
text
@d87 1
@


1.48
log
@set PBS_DEFAULT to RMSERVER_DEFAULT
@
text
@d621 4
a624 1
                n_int = string.atoi(n_string)
@


1.47
log
@validate QOS
@
text
@d20 2
@


1.46
log
@take resource Cpus from actual cpus on the node, not ConsumableCpus
@
text
@d430 6
a435 1
                new_job_step['QOS'] =  QOS
@


1.45
log
@*** empty log message ***
@
text
@d486 1
a486 1
        new_resource['Cpus'] = 0
@


1.44
log
@smp
@
text
@d46 1
@


1.43
log
@*** empty log message ***
@
text
@d25 2
d28 1
d297 12
a308 1
        spec_list = string.split(node_spec_string, '+')
d416 1
d482 5
a520 7
    # pause here...
    #step_initiatormap = job_step['initiatormap']
    #initiators_list = string.split(step_initiatormap, '+')
    #job_initiator_per_node_int = 0
    #for initiator in initiators_list :
    #    if string.atoi(initiator) > job_initiator_per_node_int :
    #        job_initiator_per_node_int = string.atoi(initiator)
a521 5
    # slow point
    #if job_step.has_key('cat_requirements_string') :
    #    new_requirements_string = job_step['cat_requirements_string']
    #else :
    #    new_requirements_string = get_requirements_string(job_step['requirements'])
a530 1
            #print "new_requirements_string (%s)" % new_requirements_string
a538 5
                    #print "requirements string: (%s)" % new_requirements_string
                    #print "resource['Cpus'] is (%s)" % resource['Cpus']
                    #print "resource['name'] is (%s)" % resource['name']
                    #print "resource['ntype_string'] is (%s)" % resource['ntype_string']
                    #print "resource['OpSys'] is (%s)" % resource['OpSys']
d548 1
a548 1
            this_resource_dict[resource['name']] = resource
d593 9
a601 1
            node_spec_list = string.split(node_spec_string, '+')
@


1.42
log
@added multiple-requirement resource spec
@
text
@d31 7
@


1.41
log
@added run_at_risk
@
text
@d13 1
d26 1
d64 1
d252 1
a252 1
            print "job has walltime"
d279 2
d282 1
a282 1
            print "Job (%s) does not have have 'nodes' in Resource_List!" % job_step_id
d287 2
a288 1
        property_list = string.split(node_spec_string, ':')
d290 52
a341 12
        new_property_list = []
        ppn_string = None
        for property in property_list[1:] :
            ppn_mo = ppn_reo.match(property)
            if ppn_mo != None :
                ppn_string = ppn_mo.group('tasks')
            else :
                new_property_list.append(property)
                requirements_string = requirements_string + ' and ' + \
                  "'" + property + "'" + " in resource['properties_list']"
        if ppn_string == None :
            ppn_string = '1'
a342 1
        new_job_step['property_list'] = property_list
d367 1
a367 1
                print "job_start_tuple (%s)" % (job_start_tuple,)
d426 2
a427 2
        new_job_step['initiatormap'] = (ppn_string + '+') * node_count
        new_job_step['initiatormap'] = new_job_step['initiatormap'][:-1]
d468 2
a469 2
        print "in get_resources_list, new_resource['State'] (%s)" % \
          new_resource['State']
d482 11
a492 2
def get_resource_list(job_step, resources_db_handle) :
    # returns list of resource objects that match job_step
d494 7
a500 24
    #job_adapter_requirement = job_step['adapter']
    #job_adapter_reo = re.compile(r"\((?P<interface>\S+),(\S+),(?P<sharing>\S+),(?P<USorIP>\S+)\)")
    #job_adapter_mo = job_adapter_reo.match(job_adapter_requirement)
    #if job_adapter_requirement == '' :
    #    ready_adapter_match_string = ''
    #else :
    #    ready_adapter_match_string = job_adapter_mo.group('interface') + \
    #      r'\(?\S+,(READY|)\)'
    # The following depends on ConfiguredClasses being in the form of
    # llstatus -l ConfiguredClasses:
    # ConfiguredClasses   = Diag9(8) Diag0(8) standby(8) low(8) normal(16) high(8)
    # rewrite for Data Access API where class names are repeated for each
    # instance of class
    #job_class_requirement = job_step['job_class']
    #job_class_search_string = r"%s\((?P<class_amount>\d+)\)" % job_class_requirement
    #job_class_reo = re.compile(job_class_search_string)
    # Find the number of initiators per node, assuming a rectangular
    # geometry.  Take the largest in the map.
    step_initiatormap = job_step['initiatormap']
    initiators_list = string.split(step_initiatormap, '+')
    job_initiator_per_node_int = 0
    for initiator in initiators_list :
        if string.atoi(initiator) > job_initiator_per_node_int :
            job_initiator_per_node_int = string.atoi(initiator)
d503 44
a546 2
    if job_step.has_key('cat_requirements_string') :
        new_requirements_string = job_step['cat_requirements_string']
d548 5
a552 37
        new_requirements_string = get_requirements_string(job_step['requirements'])
    if new_requirements_string == '' :
        compiled_nrq = compile('1', '<string>', 'eval')
    else :
        compiled_nrq = compile(new_requirements_string, '<string>', 'eval')
    for key in resources_shelf.keys() :
        to_be_continued = 0
        resource = resources_shelf[key]
        try :
            if not eval(compiled_nrq) :
                to_be_continued = 1
                #print "requirements string: (%s)" % new_requirements_string
                #print "resource['Pool'] is (%s)" % resource['Pool']
                #print "resource['Arch'] is (%s)" % resource['Arch']
                #print "resource['OpSys'] is (%s)" % resource['OpSys']
        except NameError :
            print "Bad requirements string(%s) for job (%s)!" % (job_step['requirements'], job_step['name'])
            break
        if to_be_continued == 1 :
            continue
        # Right here, need to check for number of ConfiguredClasses
        # This may also be the place to implement mult-job per node
        # by reserving Class initiators...
        #if resource['ConfiguredClasses'] == None :
        #    continue
        #job_class_mo = job_class_reo.search(resource['ConfiguredClasses'])
        #if job_class_mo == None :
        #    # resource does not have this class at all
        #    continue
        #elif string.atoi(job_class_mo.group('class_amount')) < job_initiator_per_node_int :
        #    # The resource has the class, but fewer initiators for that
        #    # class than the job needs.
        #    continue
        #if not re.search(ready_adapter_match_string, resource['Adapter']) :
        #    continue
        screened_resource_list.append(resource)
    return screened_resource_list
a559 184
def get_QOS_priority(QOS) :
    if string.atoi(QOS) < len(Catalina.QOS_PRIORITY_dict.keys()) :
        return Catalina.QOS_PRIORITY_dict[QOS]
    else :
        return 0

def get_QOS_target_expansion_factor(QOS) :
    # This returns the target expansion factor for
    # the different QOSs.
    if string.atoi(QOS) < len(Catalina.QOS_TARGETXF_dict.keys()) :
        return Catalina.QOS_TARGETXF_dict[QOS]
    else :
        return None

def get_QOS_target_queue_wait_time(QOS) :
    # This function returns a target queue wait time
    # for a given QOS.
    if string.atoi(QOS) < len(Catalina.QOS_TARGETQT_dict.keys()) :
        return Catalina.QOS_TARGETQT_dict[QOS]
    else :
        return None

def update_job_priorities (jobs_db_handle) :
    # priority calculation:
    # resource_number * Resource_Weight
    # expansion factor * Expansion_Factor_Weight
    # system queue time * System_Queue_Time_Weight
    # submit time * Submit_Time_Weight
    # QOS_priority * QOS_Priority_Weight
    # QOS_target_expansion_factor * QOS_Target_Expansion_Factor_Weight
    # QOS_target_queue_wait_time * QOS_Target_Queue_Wait_Time_Weight
    # Adjust these weights to emphasize different elements of the
    # priority calculation
    #Resource_Weight = 1100.0
    #Expansion_Factor_Weight = 10.0
    #System_Queue_Time_Weight = 0.1
    #Submit_Time_Weight = 0.0
    #QOS_Priority_Weight = 6000.0
    #QOS_Target_Expansion_Factor_Weight = 1
    #QOS_Target_Queue_Wait_Time_Weight = 1
    Resource_Weight = Catalina.RESOURCE_WEIGHT
    if Catalina.__dict__.has_key('LOCAL_ADMIN_WEIGHT') :
        Local_Admin_Weight = Catalina.LOCAL_ADMIN_WEIGHT
    else :
        Local_Admin_Weight = 0.0
    if Catalina.__dict__.has_key('LOCAL_USER_WEIGHT') :
        Local_User_Weight = Catalina.LOCAL_USER_WEIGHT
    else :
        Local_User_Weight = 0.0
    Expansion_Factor_Weight = Catalina.EXPANSION_FACTOR_WEIGHT
    System_Queue_Time_Weight = Catalina.SYSTEM_QUEUE_TIME_WEIGHT
    Submit_Time_Weight = Catalina.SUBMIT_TIME_WEIGHT
    Wall_Time_Weight = Catalina.WALL_TIME_WEIGHT
    QOS_Priority_Weight = Catalina.QOS_PRIORITY_WEIGHT
    QOS_Target_Expansion_Factor_Weight = Catalina.QOS_TARGET_EXPANSION_FACTOR_WEIGHT
    QOS_Target_Queue_Wait_Time_Weight = Catalina.QOS_TARGET_QUEUE_WAIT_TIME_WEIGHT
    jobs_shelf = jobs_db_handle[0]
    for key in jobs_shelf.keys() :
        # Set up a dict to store priority calculation terms for later reports
        priority_element_dict = {
          'Resource_Weight'                    : Resource_Weight,
          'Local_Admin_Weight'                 : Local_Admin_Weight,
          'Local_User_Weight'                  : Local_User_Weight,
          'Expansion_Factor_Weight'            : Expansion_Factor_Weight,
          'System_Queue_Time_Weight'           : System_Queue_Time_Weight,
          'Wall_Time_Weight'                   : Wall_Time_Weight,
          'Submit_Time_Weight'                 : Submit_Time_Weight,
          'QOS_Priority_Weight'                : QOS_Priority_Weight,
          'QOS_Target_Expansion_Factor_Weight' : QOS_Target_Expansion_Factor_Weight,
          'QOS_Target_Queue_Wait_Time_Weight'  : QOS_Target_Queue_Wait_Time_Weight
        }

        temp_job = jobs_shelf[key]

        # Get number of resources from initiatormap
        resourcemap_list = string.split(jobs_shelf[key]['initiatormap'], '+')
        resource_number = float(len(resourcemap_list))

        # Get local priority from local_priority_string
        if temp_job.has_key('local_admin_priority_string') and \
          temp_job['local_admin_priority_string'] != None :
            try :
                local_admin_float = float(temp_job['local_admin_priority_string'])
            except :
                local_admin_float = 0.0
        else :
            local_admin_float = 0.0
        if Catalina.DEBUGJOB != None and temp_job['name'] != None and temp_job['name'] == Catalina.DEBUGJOB :
            print "local_admin_float (%s)" % local_admin_float
            print "local_admin_priority_string (%s)" % temp_job['local_admin_priority_string']
        if temp_job.has_key('local_user_priority_string') and \
          temp_job['local_user_priority_string'] != None :
            try :
                local_user_float = float(temp_job['local_user_priority_string'])
                if local_user_float > 0.0 :
                    local_user_float = 0.0
            except :
                local_user_float = 0.0
        else :
            local_user_float = 0.0


        # Calculate expansion factor
        if temp_job['wall_clock_limit'] == None :
            expansion_factor = 0
        else :
            #print "temp_job['wall_clock_limit'] (%s)" % \
            #  temp_job['wall_clock_limit']
            expansion_factor = \
              ( ( Catalina.Now_float -
                  float(temp_job['speculative_system_queue_time']) + \
                float(temp_job['wall_clock_limit']) ) / \
              float(temp_job['wall_clock_limit']) )

        # Calculate queue wait time
        queue_wait_time = Catalina.Now_float - float(temp_job['speculative_system_queue_time'])

        # Calculate submit wait time
        submit_wait_time = Catalina.Now_float - float(temp_job['SubmitTime'])

        # Get wall clock time
        wall_clock_time = temp_job['wall_clock_limit']

        # Get QOS priority
        QOS_priority = float(get_QOS_priority(temp_job['QOS']))

        # Get QOS target expansion factor
        QOS_target_expansion_factor = get_QOS_target_expansion_factor(temp_job['QOS'])
        if QOS_target_expansion_factor == None :
            QOS_target_xf_value = 0
        else :
            if expansion_factor >= QOS_target_expansion_factor :
                QOS_target_xf_value = float(Catalina.QOS_MAX_PRIORITY_dict[temp_job['QOS']])
            else :
                QOS_target_xf_value = 1 / (QOS_target_expansion_factor - expansion_factor)
            if QOS_target_xf_value > float(Catalina.QOS_MAX_PRIORITY_dict[temp_job['QOS']]) :
                QOS_target_xf_value = float(Catalina.QOS_MAX_PRIORITY_dict[temp_job['QOS']])
        # Get QOS target queue time
        QOS_target_queue_wait_time = get_QOS_target_queue_wait_time(temp_job['QOS'])
        if QOS_target_queue_wait_time == None :
            QOS_target_qwt_value = 0
        else :
            if queue_wait_time >= QOS_target_queue_wait_time :
                QOS_target_qwt_value = float(Catalina.QOS_MAX_PRIORITY_dict[temp_job['QOS']])
            else :
                QOS_target_qwt_value = 1 / (QOS_target_queue_wait_time - queue_wait_time)
            if QOS_target_qwt_value > float(Catalina.QOS_MAX_PRIORITY_dict[temp_job['QOS']]) :
                QOS_target_qwt_value = float(Catalina.QOS_MAX_PRIORITY_dict[temp_job['QOS']])

        priority_element_dict['resource_number'] = resource_number
        priority_element_dict['local_admin_float'] = local_admin_float
        priority_element_dict['local_user_float'] = local_user_float
        priority_element_dict['expansion_factor'] = expansion_factor
        priority_element_dict['queue_wait_time'] = queue_wait_time
        priority_element_dict['submit_wait_time'] = submit_wait_time
        priority_element_dict['wall_clock_time'] = wall_clock_time
        priority_element_dict['QOS_priority'] = QOS_priority
        priority_element_dict['QOS_target_xf_value'] = QOS_target_xf_value
        priority_element_dict['QOS_target_qwt_value'] = QOS_target_qwt_value

        if temp_job['system_priority_int'] != None :
            priority = float( Catalina.MAXPRIORITY + \
              temp_job['system_priority_int'] )
        else :
            priority = \
                resource_number * Resource_Weight + \
                local_admin_float * Local_Admin_Weight + \
                local_user_float * Local_User_Weight + \
                expansion_factor * Expansion_Factor_Weight + \
                queue_wait_time * System_Queue_Time_Weight + \
                submit_wait_time * Submit_Time_Weight + \
                wall_clock_time * Wall_Time_Weight + \
                QOS_priority * QOS_Priority_Weight + \
                QOS_target_xf_value * QOS_Target_Expansion_Factor_Weight + \
                QOS_target_qwt_value * QOS_Target_Queue_Wait_Time_Weight
            if Catalina.QOS_MAX_PRIORITY_dict.has_key(temp_job['QOS']) :
                max_pri = float(Catalina.QOS_MAX_PRIORITY_dict[temp_job['QOS']])
            else :
                max_pri = Catalina.MAXPRIORITY
            if priority > max_pri - max_pri * 0.1 :
                priority =  (priority * max_pri)/(priority + max_pri * 0.1)
	Catalina.update_object_attribute('priority', priority, temp_job, jobs_db_handle)
	Catalina.update_object_attribute('priority_element_dict', priority_element_dict, temp_job, jobs_db_handle)

d598 3
@


1.40
log
@use 'pcpus' if 'np' is not present
@
text
@d369 4
@


1.39
log
@for jobs with down nodes, use logger instead of sending email
@
text
@d407 4
a410 1
        new_resource['Cpus'] =  string.atoi(dict['np'][1])
@


1.38
log
@took out bad job purge info for LL
@
text
@d209 4
a212 4
                subject = "Job has Down Nodes %s, %s" % \
                  (job['name'], job['user'])
                recipient = Catalina.MAIL_RECIPIENT
                Catalina.warn(message, subject, recipient)
@


1.37
log
@changed IGNORE to @@IGNORE
@
text
@d198 1
a198 1
job (%s) (user %s), in state %s has LoadL down nodes:
d200 2
a201 3
If it does have Down nodes, check to see if the job is in state
Remove Pending (RP in llq).  If so, the job may be stuck waiting
for a response from the down nodes.  It may be necessary to issue:
d205 5
a209 5
                for host in down_hosts_list :
                    purge_line = "\n/usr/lpp/LoadL/full/bin/llctl -h %s purge %s" % \
                      (jobs_dict[job['name']]['fromhost'], host)
                    message = message + purge_line
                subject = "Job has LoadLeveler Down Nodes %s, %s" % \
@


1.36
log
@strip '@@host' off of jobowner, if USERNAMESUFFIX == 'IGNORE'
@
text
@d240 1
a240 1
        if Catalina.USERNAMESUFFIX == 'IGNORE' :
@


1.35
log
@split properties up on ','
@
text
@d240 4
a243 1
        new_job_step['user'] = runjob_dict[job_step_id]['Job_Owner'][1]
@


1.34
log
@handle lack of comment attribute from job.
qualify Now_float with Catalina prefix
@
text
@d408 1
a408 1
            new_resource['properties_list'] = dict['properties']
@


1.33
log
@added job_start_warns_int to initialize_job
@
text
@d299 4
a302 1
            job_comment = runjob_dict[job_step_id]['comment'][1]
d339 1
a339 1
                new_job_step['Dispatch_Time'] = Now_float - walltime_sec
@


1.32
log
@added check for Catalina.QOS_MAX_PRIORITY_dict.has_key(temp_job['QOS'])
@
text
@d70 1
@


1.31
log
@if node nodes and nodect in Resource_list, assume 1:ppn=1
@
text
@d675 4
a678 1
            max_pri = float(Catalina.QOS_MAX_PRIORITY_dict[temp_job['QOS']])
@


1.30
log
@set ConfiguredClasses to DEFAULTJOBCLASS
@
text
@d275 4
a278 2
            break
        node_spec_string = runjob_dict[job_step_id]['Resource_List']['nodes']
d363 8
a370 2
        node_count = string.atoi(runjob_dict[job_step_id]['Resource_List']['nodect'])
        new_job_step['node_spec_string'] = runjob_dict[job_step_id]['Resource_List']['nodes']
@


1.29
log
@put in error handling for no Resource_List and not 'nodes' in Resource_List
@
text
@d38 1
a38 1
    new_resource['ConfiguredClasses_list'] = ['default','DEFAULT']
@


1.28
log
@if necessary, use resources_used.walltime to calculate job start time
@
text
@d82 1
a82 1
        step_dict = {}
d273 3
@


1.27
log
@parse out job start time from either the PBS sched comment or the
Catalina start comment
@
text
@a92 2
                    print "Resource_List key (%s), value (%s)" % \
                      (name_value_list[1], name_value_list[2])
d96 7
a102 2
                    #print "Resource_List key (%s), value (%s)" % \
                    #  (name_value_list[1], name_value_list[2])
d323 8
@


1.26
log
@get start time from comment of running job
if resource state is not in rm_to_cat dict, then set to 'Down'
@
text
@d230 2
a231 2
    #job_start_reo = re.compile(r"Job started on (?P<date>\w+\s+\w+\s+\w+) at (?P<time>\d\d:\d\d)")
    #LLQ = '/usr/lpp/LoadL/full/bin/llq -l | /usr/bin/grep -e "Job Step Id" -e Specify -e "Adapter Requirement"'
d300 22
a321 14
            job_start_tuple = time.strptime(
              job_comment,
              "Job started on %a %b %d at %H:%M"
              )
            job_start_tuple = (Now_year,) + job_start_tuple[1:-1] + (-1,)
            print "job_start_tuple (%s)" % (job_start_tuple,)
            job_start_float = time.mktime(job_start_tuple)
            # if the guessed year makes the job start time more than
            # 30 days in the future, assume it should be the previous year
            if job_start_float > Catalina.Now_float + 30*24*60*60 :
                print "job_start_float (%s) > Catalina.Now_float (%s)" % (time.asctime(time.localtime(job_start_float)), time.asctime(time.localtime(Catalina.Now_float)))
                job_start_tuple = (Now_year - 1,) + job_start_tuple[1:]
            job_start_float = time.mktime(job_start_tuple)
            new_job_step['Dispatch_Time'] = job_start_float
@


1.25
log
@removed Account_Name bug.  needs to be tested
@
text
@d23 1
d98 2
a99 2
                    print "Resource_List key (%s), value (%s)" % \
                      (name_value_list[1], name_value_list[2])
d227 2
d230 1
d245 1
a245 1
            print "raw_walltime_string (%s)" % raw_walltime_string
d290 25
a314 1
            new_job_step['Dispatch_Time'] = string.atof(runjob_dict[job_step_id]['mtime'][1])
d375 5
a379 2
        new_resource['State'] = \
          Catalina.RM_TO_CAT_RESOURCE_dict[dict['state'][1]]
d576 2
a577 2
            print "temp_job['wall_clock_limit'] (%s)" % \
              temp_job['wall_clock_limit']
@


1.24
log
@check for first node spec properties
@
text
@a254 1
        new_job_step['account'] = runjob_dict[job_step_id]['Account_Name'][1]
@


1.23
log
@use mtime as Dispatch_Time for already running jobs.
@
text
@d264 20
a283 1
        new_job_step['requirements'] = "resource['ntype_string'] == 'cluster'"
d314 1
a314 1
        new_job_step['initiatormap'] = '1+' * node_count
d346 2
@


1.22
log
@removed CANCELCMD
@
text
@d268 1
@


1.21
log
@put in check for no ppn
@
text
@a18 2
TESTJOB='testjob.PBS'
CANCELCMD='/usr/local/bin/qdel'
d111 1
a111 1
    cmd_string = CANCELCMD + ' ' + job_step['name']
@


1.20
log
@drop resource off node_spec
@
text
@a19 1
SUBMITCMD='/usr/local/bin/qsub -q low'
d631 1
a631 2
                ppn_string = split_tuple[1]
                if ppn_reo.match(ppn_string) == None :
d633 4
@


1.19
log
@modified generation of node_destination_string for multiple
tasks/node.  does not respect any other requirements
@
text
@d630 3
a632 1
                n_string, ppn_string = string.split(node_spec, ':')
@


1.18
log
@put in checks for completion of qm and qj
@
text
@d296 1
d604 1
d625 24
a648 1
            node_destination_string = string.join(node_list, '+')
@


1.17
log
@modified SUBMIT_OUTPUT_PATTERN, JOB_UPDATE_ATTRIBUTE_list,
ConfiguredClasses
group
@
text
@d75 2
d80 4
d109 2
d306 2
d309 4
d336 2
@


1.16
log
@use start_count_int instead of start_returncode_int
@
text
@d23 1
a23 1
SUBMIT_OUTPUT_PATTERN=r'^(?P<job_id>\d+\.\w+)'
a26 2
  'local_admin_priority_string',
  'local_user_priority_string'
d40 1
a40 1
    new_resource['ConfiguredClasses_list'] = None
d251 2
a252 1
        new_job_step['group'] = runjob_dict[job_step_id]['egroup'][1]
d491 3
@


1.15
log
@changed from ll_start_job to pbs_asyrunjob
@
text
@d598 2
a599 2
            if reservation.has_key('start_returncode_int') and \
              reservation['start_returncode_int'] == 0 :
d649 8
a656 7
                Catalina.update_object_attribute(
                  'start_returncode_int',
                  return_code_int,
                  reservation,
                  reservations_db_handle)
                print "setting start_returncode_int to (%s) for (%s)" % \
                  (return_code_int, reservation['job_runID'])
@


1.14
log
@remember started job
@
text
@d31 1
a31 1
start_job_returncode_reo = re.compile("^rc from ll_start_job is >(?P<code>\d+)<$", re.MULTILINE)
d639 1
a639 1
              'rc from ll_start_job is >0<\012'
@


1.13
log
@changed priority to non-identical for large values
@
text
@d31 2
d584 1
d598 3
d618 1
a618 1
            jobs_to_run[job_stepid] = runstring
d624 2
d627 1
a627 1
        cmd = RUNJOB + ' ' + jobs_to_run[job]
d633 8
d642 18
@


1.12
log
@added local_admin and local_user to update attributes
@
text
@d40 1
a40 1
    new_resource['ConfiguredClasses'] = None
d271 1
a271 1
            if fields[0] == 'Catalina_res_bind' :
a531 1
                #QOS_target_xf_value = float(Catalina.MAXPRIORITY)
d535 2
a536 1

a542 1
                #QOS_target_qwt_value = float(Catalina.MAXPRIORITY)
d546 2
d575 3
a577 2
            if priority > float(Catalina.QOS_MAX_PRIORITY_dict[temp_job['QOS']]) :
                priority = float(Catalina.QOS_MAX_PRIORITY_dict[temp_job['QOS']])
@


1.11
log
@synced up with Catalina_LL.py.dist, but untested
@
text
@d24 6
a29 1
JOB_UPDATE_ATTRIBUTE_list = ['state', 'allocated_hosts']
@


1.10
log
@cleaned out some commented code in get_resources_list
@
text
@a21 14
NODERESTCODE="""
if input_tuple[0]['ntype_string'] != 'cluster' :
    result = 'NonCluster'
elif resource['State'] == 'Down' :
    result = 'Down'
elif resource['State'] == 'None' :
    result = 'None'
elif resource['State'] == None :
    result = None
elif resource['State'] == 'Unknown' :
    result = 'Unknown'
else :
    result = 0
"""
d275 6
d332 1
a332 1
    #      r'\(\S+,(READY|)\)'
d439 8
d450 1
d459 2
d463 1
a469 13
        priority_element_dict['Resource_Weight'] = Resource_Weight
        priority_element_dict['Expansion_Factor_Weight'] = \
          Expansion_Factor_Weight
        priority_element_dict['System_Queue_Time_Weight'] = \
          System_Queue_Time_Weight
        priority_element_dict['Submit_Time_Weight'] = \
          Submit_Time_Weight
        priority_element_dict['QOS_Priority_Weight'] = QOS_Priority_Weight
        priority_element_dict['QOS_Target_Expansion_Factor_Weight'] = \
          QOS_Target_Expansion_Factor_Weight
        priority_element_dict['QOS_Target_Queue_Wait_Time_Weight'] = \
          QOS_Target_Queue_Wait_Time_Weight

d476 21
d515 3
d544 2
d549 1
d560 2
d565 1
@


1.9
log
@not tested
@
text
@a313 40
        #class_instance_list = string.split(dict['ConfiguredClasses'], '+')
        #configured_classes_list = []
        #configured_classes_string = ''
        #old_instance = class_instance_list[0]
        #instance_counter = 1
        #irange = range(len(class_instance_list))
        #for i in irange :
        #    instance = class_instance_list[i]
        #    if instance != old_instance :
        #        #configured_classes_list.append("%s(%s)" % (old_instance, instance_counter))
        #        configured_classes_string = configured_classes_string + ("%s(%s)" % (old_instance, instance_counter - 1))
        #        instance_counter = 1
        #        old_instance = instance
        #    elif i == irange[-1] :
        #        configured_classes_string = configured_classes_string + ("%s(%s)" % (old_instance, instance_counter ))
        #    instance_counter = instance_counter + 1
        ##configured_classes_string = "".join(configured_classes_list)
        #new_resource['ConfiguredClasses'] =  configured_classes_string
        #new_resource['AvailableClasses'] =  dict['AvailableClasses']
        #class_instance_list = string.split(dict['AvailableClasses'], '+')
        ##available_classes_list = []
        #available_classes_string = ''
        #old_instance = class_instance_list[0]
        #instance_counter = 1
        #irange = range(len(class_instance_list))
        #for i in irange :
        #    instance = class_instance_list[i]
        #    if instance != old_instance :
        #        #available_classes_list.append("%s(%s)" % (old_instance, instance_counter))
        #        available_classes_string = available_classes_string + ("%s(%s)" % (old_instance, instance_counter - 1))
        #        instance_counter = 1
        #        old_instance = instance
        #    elif i == irange[-1] :
        #        available_classes_string = available_classes_string + ("%s(%s)" % (old_instance, instance_counter))
        #    instance_counter = instance_counter + 1
        ##available_classes_string = "".join(available_classes_list)
        #new_resource['AvailableClasses'] =  available_classes_string
        #new_resource['Feature'] =  dict['Feature']
        #new_resource['Max_Starters'] =  string.atoi(dict['Max_Starters'])
        #new_resource['Memory'] =  string.atoi(dict['Memory'])
a315 1
        #new_resource['State'] = dict['state'][1]
a322 27
    #LLSTATUS = '/usr/lpp/LoadL/full/bin/llstatus -l'
    #resources = []
    #found_start = 0
    #resource_string = ''
    #resource_reo = re.compile( r"""(^\s*Name\s*=\ (?P<Name>\S+)$)
    #        ((.|\n)*)
    #        (^\s*Adapter\s*=\ (?P<Adapter>.*?)$)
    #        ((.|\n)*)"""
    #    ,re.MULTILINE | re.VERBOSE)
    #delimit_reo = re.compile(r"^===============================================================================$")
    #for line in  os.popen(LLSTATUS).readlines() :
    #    resource_string = resource_string + line
    #    line_mo = None
    #    line_mo = delimit_reo.match(line)
    #    if line_mo != None :
    #        if found_start == 1 :
    #            # parse the resource_string
    #            resource_mo = resource_reo.search(resource_string)
    #            if resource_mo == None :
    #                print "resource_mo is None"
    ##                print "resource_string is (%s)" % resource_string
    #            else :
    #                resource_name =  resource_mo.group('Name')
    #                resources_dict[resource_name]['Adapter'] =  resource_mo.group('Adapter')
    #            # clear the old job_string, store the old new_job_step
    #            resource_string = ''
    #        found_start = 1
@


1.8
log
@removed get_accepted_nodes_list
@
text
@a72 1
    #new_job_step['cat_requirements_string'] = None
a84 7
    #stepid_reo = re.compile(r"^stepid:(?P<stepid>(?P<fromhost>.*)\.(?P<cluster>\d+)\.(?P<proc>\d+))$")
    #initiatormap_reo = re.compile(r"^initiatormap:(?P<initiatormap>.*)$")
    #comment_reo = re.compile(r"^comment:(?P<comment>.*)$")
    #state_reo = re.compile(r"^state:(?P<state>.*)$")
    #dispatchtime_reo = re.compile(r"^dispatchtime:(?P<dispatchtime>\d*)$")
    #submittime_reo = re.compile(r"^submittime:(?P<submittime>\d*)$")
    #completiontime_reo = re.compile(r"^completiontime:(?P<completiontime>\d*)$")
d169 2
a170 1
                if resources_dict[host]['State'] == 'Down' and \
d237 4
a240 1
        new_job_step['state'] = Catalina.RM_TO_CAT_JOB_dict[runjob_dict[job_step_id]['job_state'][1]]
a267 4
        #requirements_map = runjob_dict[job_step_id]['requirementsmap']
        #single_requirements_list = string.split(requirements_map, '+')
        #new_job_step['requirements'] = single_requirements_list[0]
        #new_job_step['adapter'] = llq_job_step_adapter
a268 4
        #new_job_step['fromhost'] = runjob_dict[job_step_id]['fromhost']
        #new_job_step['cluster'] = runjob_dict[job_step_id]['cluster']
        #new_job_step['proc'] = runjob_dict[job_step_id]['proc']
        #new_job_step['Dispatch_Time'] = string.atof(runjob_dict[job_step_id]['dispatchtime'])
a269 2
        #if runjob_dict[job_step_id].has_key('completiontime') :
        #    new_job_step['completion_time'] = string.atof(runjob_dict[job_step_id]['completiontime'])
a275 1
        #new_job_step['comment'] = runjob_dict[job_step_id]['comment']
@


1.7
log
@added ntype cluster check to NODERESTCODE
@
text
@a83 28
def get_accepted_nodes_list(node_restriction_code, resource_db_handle) :
    dict = resource_db_handle[0]
    resource_list = dict.values()
    accepted_nodes_list = []
    for resource in resource_list :
        if node_restriction_code != None :
            print "node_restriction_code (%s)" % node_restriction_code
            input_tuple = (resource,)
            acceptance = apply_policy_code(node_restriction_code, input_tuple)
        elif resource['State'] == 'Down' :
            acceptance = 'Down'
        elif resource['State'] == 'Drain' :
            acceptance = 'Drain'
        elif resource['State'] == 'Drained' :
            acceptance = 'Drained'
        elif resource['State'] == 'None' :
            acceptance = 'None'
        elif resource['State'] == None :
            acceptance = None
        elif resource['State'] == 'Unknown' :
            acceptance = 'Unknown'
        else :
            acceptance = 0
        if acceptance != 0 :
            continue
        accepted_nodes_list.append(resource['name'])
    return accepted_nodes_list

@


1.6
log
@modified NODERESTCODE to check node state
@
text
@d23 3
a25 1
if resource['State'] == 'Down' :
@


1.5
log
@check for Account_Name
@
text
@d22 12
a33 1
NODERESTCODE="if input_tuple[0]['ntype_string'] == 'cluster' : result = 0"
@


1.4
log
@moved RUNJOB to run_jobs
@
text
@d24 1
a24 1
SUBMIT_OUTPUT_PATTERN=r'^(?P<job_id>\\\d+\\\.\\\w+)'
d274 4
@


1.3
log
@*** empty log message ***
@
text
@a24 1
RUNJOB='___RUNJOB_PLACEHOLDER___'
d648 1
@


1.2
log
@*** empty log message ***
@
text
@d25 1
a25 1
RUNJOB='rj_PBS'
d109 1
a109 1
    cmd = Catalina.HOMEDIR + '/getinitmap'
d324 1
a324 1
    QUERYMACHINES = Catalina.QUERYMACHINES
@


1.1
log
@Initial revision
@
text
@d1 3
a3 4
# SP-specific Catalina names
# get node info with llstatus -l
# get job info with llq -l
# get initiatormap from queryjob2 (Data Access API)
a4 4
# - Requirements expression (from queryjob2)
# - Adapter Requirement (from llq -l)
# - initiator map (from queryjob2)
# - job class (queryjob2)
a7 1
# Don't see how to get Adapter Requirement from API...
d19 9
d72 28
d139 2
a140 4
    #LoadL_cancel = '/usr/lpp/LoadL/full/bin/llcancel'
    PBS_cancel = '/usr/local/bin/qdel'
    cmd_string = LoadL_cancel + ' ' + job_step['name']
    output = 'qdel: Cancel command has been sent to the central manager.'
d650 1
a650 1
    RUNJOB = Catalina.HOMEDIR + '/runjob'
@
